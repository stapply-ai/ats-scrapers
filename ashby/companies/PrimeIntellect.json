{"jobs": [{"id": "ee13090e-3fea-40f0-b785-19316f52bf08", "title": "Research Engineer - Reinforcement Learning", "department": "Research", "team": "Research", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [{"location": "Remote", "address": {"postalAddress": {"addressCountry": "United States"}}}], "publishedAt": "2024-08-19T13:59:42.712+00:00", "isListed": true, "isRemote": false, "address": {"postalAddress": {"addressRegion": "California", "addressCountry": "United States", "addressLocality": "San Francisco"}}, "jobUrl": "https://jobs.ashbyhq.com/PrimeIntellect/ee13090e-3fea-40f0-b785-19316f52bf08", "applyUrl": "https://jobs.ashbyhq.com/PrimeIntellect/ee13090e-3fea-40f0-b785-19316f52bf08/application", "descriptionHtml": "<p style=\"min-height:1.5em\">Prime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.</p><p style=\"min-height:1.5em\">As a Research Engineer in our Reasoning team, you'll play a crucial role in shaping our technological direction, focusing on our test-time compute scaling research ideas. If you love working with synthetic data and teach LLMs reasoning abilities, this role is for you.<br />For more details about the project you would be working on, check out our <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.primeintellect.ai/blog/intellect-math\">outlook on decentralized training in the inference-compute paradigm.</a></p><p style=\"min-height:1.5em\"></p><h2><strong>Responsibilities</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Lead and participate in novel research to build a massive scale synthetic data generation pipeline and orchestration solution</p></li><li><p style=\"min-height:1.5em\">Optimize the performance, cost, and resource utilization of AI inference workloads by leveraging the most recent advances for compute &amp; memory optimization techniques.</p></li><li><p style=\"min-height:1.5em\">Contribute to the development of our open-source libraries and frameworks for synthetic data generation and distributed RL frameworks.</p></li><li><p style=\"min-height:1.5em\">Publish research in top-tier AI conferences such as ICML &amp; NeurIPS.</p></li><li><p style=\"min-height:1.5em\">Distill highly technical project outcomes in layman approachable technical blogs to our customers and developers.</p></li><li><p style=\"min-height:1.5em\">Stay up-to-date with the latest advancements in AI/ML infrastructure and tools, synthetic data gen research and proactively identify opportunities to enhance our platform's capabilities and user experience.</p></li></ul><h2><strong>Requirements</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Strong background in AI/ML engineering, with extensive experience in designing and implementing end-to-end pipelines for the inference or training of large-scale AI models.</p></li><li><p style=\"min-height:1.5em\">Deep expertise in distributed inference techniques and frameworks (e.g. vllm, sglang) for optimizing the performance and scalability of AI workloads.</p></li><li><p style=\"min-height:1.5em\">Solid understanding of MLOps best practices, including model versioning, experiment tracking, and continuous integration/deployment (CI/CD) pipelines.</p></li><li><p style=\"min-height:1.5em\">Passion for advancing the state-of-the-art in reasoning and democratizing access to AI capabilities for researchers, developers, and businesses worldwide.</p></li><li><p style=\"min-height:1.5em\">If you're not familiar with these, but feel like that you can contribute to our mission and you're a high-energy person, get familiar with these resources (<a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://a.co/d/frW8MHY\">here</a>, <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://a.co/d/4WRhR0Y\">here</a> and <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://github.com/stas00/ml-engineering/tree/master\">here</a>) and please reach out!</p></li></ul><h2><strong>Benefits &amp; Perks</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Competitive compensation, including equity incentives, aligning your success with the growth and impact of Prime Intellect.</p></li><li><p style=\"min-height:1.5em\">Flexible work arrangements, with the option to work remotely or in-person at our offices in San Francisco.</p></li><li><p style=\"min-height:1.5em\">Visa sponsorship and relocation assistance for international candidates.</p></li><li><p style=\"min-height:1.5em\">Quarterly team off-sites, hackathons, conferences and learning opportunities.</p></li><li><p style=\"min-height:1.5em\">Opportunity to work with a talented, hard-working and mission-driven team, united by a shared passion for leveraging technology to accelerate science and AI.</p></li></ul><p style=\"min-height:1.5em\">We recently raised <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.primeintellect.ai/blog/fundraise\">$15mm in funding</a> (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.</p><p style=\"min-height:1.5em\">If you're excited about the opportunity to build the foundation for the future of decentralized AI and create a platform that empowers developers and researchers to push the boundaries of what's possible, we'd love to hear from you.</p>", "descriptionPlain": "Prime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.\n\nAs a Research Engineer in our Reasoning team, you'll play a crucial role in shaping our technological direction, focusing on our test-time compute scaling research ideas. If you love working with synthetic data and teach LLMs reasoning abilities, this role is for you.\nFor more details about the project you would be working on, check out our outlook on decentralized training in the inference-compute paradigm. https://www.primeintellect.ai/blog/intellect-math\n\n\nRESPONSIBILITIES\n\n - Lead and participate in novel research to build a massive scale synthetic data generation pipeline and orchestration solution\n\n - Optimize the performance, cost, and resource utilization of AI inference workloads by leveraging the most recent advances for compute & memory optimization techniques.\n\n - Contribute to the development of our open-source libraries and frameworks for synthetic data generation and distributed RL frameworks.\n\n - Publish research in top-tier AI conferences such as ICML & NeurIPS.\n\n - Distill highly technical project outcomes in layman approachable technical blogs to our customers and developers.\n\n - Stay up-to-date with the latest advancements in AI/ML infrastructure and tools, synthetic data gen research and proactively identify opportunities to enhance our platform's capabilities and user experience.\n\n\nREQUIREMENTS\n\n - Strong background in AI/ML engineering, with extensive experience in designing and implementing end-to-end pipelines for the inference or training of large-scale AI models.\n\n - Deep expertise in distributed inference techniques and frameworks (e.g. vllm, sglang) for optimizing the performance and scalability of AI workloads.\n\n - Solid understanding of MLOps best practices, including model versioning, experiment tracking, and continuous integration/deployment (CI/CD) pipelines.\n\n - Passion for advancing the state-of-the-art in reasoning and democratizing access to AI capabilities for researchers, developers, and businesses worldwide.\n\n - If you're not familiar with these, but feel like that you can contribute to our mission and you're a high-energy person, get familiar with these resources (here https://a.co/d/frW8MHY, here https://a.co/d/4WRhR0Y and here https://github.com/stas00/ml-engineering/tree/master) and please reach out!\n\n\nBENEFITS & PERKS\n\n - Competitive compensation, including equity incentives, aligning your success with the growth and impact of Prime Intellect.\n\n - Flexible work arrangements, with the option to work remotely or in-person at our offices in San Francisco.\n\n - Visa sponsorship and relocation assistance for international candidates.\n\n - Quarterly team off-sites, hackathons, conferences and learning opportunities.\n\n - Opportunity to work with a talented, hard-working and mission-driven team, united by a shared passion for leveraging technology to accelerate science and AI.\n\nWe recently raised $15mm in funding https://www.primeintellect.ai/blog/fundraise (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.\n\nIf you're excited about the opportunity to build the foundation for the future of decentralized AI and create a platform that empowers developers and researchers to push the boundaries of what's possible, we'd love to hear from you.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "c074bdd9-bee2-4ee9-ae03-aa8f7537682c", "title": "Member of Technical Staff - Full Stack", "department": "Engineering", "team": "Engineering", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [{"location": "Remote", "address": {"postalAddress": {"addressCountry": "United States"}}}], "publishedAt": "2024-12-06T23:50:32.305+00:00", "isListed": true, "isRemote": false, "address": {"postalAddress": {"addressRegion": "California", "addressCountry": "United States", "addressLocality": "San Francisco"}}, "jobUrl": "https://jobs.ashbyhq.com/PrimeIntellect/c074bdd9-bee2-4ee9-ae03-aa8f7537682c", "applyUrl": "https://jobs.ashbyhq.com/PrimeIntellect/c074bdd9-bee2-4ee9-ae03-aa8f7537682c/application", "descriptionHtml": "<h2><strong>Building the Future of Decentralized AI Development</strong></h2><p style=\"min-height:1.5em\">Prime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.</p><p style=\"min-height:1.5em\">We recently raised <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.primeintellect.ai/blog/fundraise\">$15mm in funding</a> (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.</p><p style=\"min-height:1.5em\"></p><h2><strong>Role Impact</strong></h2><p style=\"min-height:1.5em\">This is a hybrid role spanning both our developer platform and infrastructure layers. You'll work on two key areas:</p><p style=\"min-height:1.5em\">1. Our developer-facing platform for AI workload management</p><p style=\"min-height:1.5em\">2. The underlying distributed infrastructure that powers our training systems </p><p style=\"min-height:1.5em\"></p><h2><strong>Core Technical Responsibilities</strong></h2><p style=\"min-height:1.5em\"><strong>Platform Development</strong></p><p style=\"min-height:1.5em\">- Build intuitive web interfaces for AI workload management and monitoring</p><p style=\"min-height:1.5em\">- Develop REST APIs and backend services in Python</p><p style=\"min-height:1.5em\">- Create real-time monitoring and debugging tools</p><p style=\"min-height:1.5em\">- Implement user-facing features for resource management and job control</p><p style=\"min-height:1.5em\"><strong>Infrastructure Development</strong></p><p style=\"min-height:1.5em\">- Design and implement distributed training infrastructure in Rust</p><p style=\"min-height:1.5em\">- Build high-performance networking and coordination components</p><p style=\"min-height:1.5em\">- Create infrastructure automation pipelines with Ansible</p><p style=\"min-height:1.5em\">- Manage cloud resources and container orchestration</p><p style=\"min-height:1.5em\">- Implement scheduling systems for heterogeneous hardware (CPU, GPU, TPU)</p><p style=\"min-height:1.5em\"></p><h2>Technical Requirements</h2><p style=\"min-height:1.5em\"><strong>Platform Skills</strong></p><p style=\"min-height:1.5em\">- Strong Python backend development (FastAPI, async)</p><p style=\"min-height:1.5em\">- Modern frontend development (TypeScript, React/Next.js, Tailwind)</p><p style=\"min-height:1.5em\">- Experience building developer tools and dashboards</p><p style=\"min-height:1.5em\">- RESTful API design and implementation</p><p style=\"min-height:1.5em\"><strong>Infrastructure Skills</strong></p><p style=\"min-height:1.5em\">- Systems programming experience with Rust</p><p style=\"min-height:1.5em\">- Infrastructure automation (Ansible, Terraform)</p><p style=\"min-height:1.5em\">- Container orchestration (Kubernetes)</p><p style=\"min-height:1.5em\">- Cloud platform expertise (GCP preferred)</p><p style=\"min-height:1.5em\">- Observability tools (Prometheus, Grafana) </p><p style=\"min-height:1.5em\"></p><h2>Nice to Have</h2><p style=\"min-height:1.5em\">- Experience with GPU computing and ML infrastructure</p><p style=\"min-height:1.5em\">- Knowledge of AI/ML model architecture and training</p><p style=\"min-height:1.5em\">- High-performance networking implementation</p><p style=\"min-height:1.5em\">- Open-source infrastructure contributions</p><p style=\"min-height:1.5em\">- WebSocket/real-time systems experience </p><p style=\"min-height:1.5em\"></p><h2>What We Offer</h2><p style=\"min-height:1.5em\">- Competitive compensation with significant equity incentives</p><p style=\"min-height:1.5em\">- Flexible work arrangement (remote or San Francisco office)</p><p style=\"min-height:1.5em\">- Full visa sponsorship and relocation support</p><p style=\"min-height:1.5em\">- Professional development budget for courses and conferences</p><p style=\"min-height:1.5em\">- Regular team off-sites and conference attendance</p><p style=\"min-height:1.5em\">- Opportunity to shape the future of decentralized AI development </p><p style=\"min-height:1.5em\"></p><h2>Growth Opportunity</h2><p style=\"min-height:1.5em\">You'll join a team of experienced engineers and researchers working on cutting-edge problems in AI infrastructure. We believe in open development and encourage team members to contribute to the broader AI community through research and open-source contributions.</p><p style=\"min-height:1.5em\">We value potential over perfection - if you're passionate about democratizing AI development and have experience in either platform or infrastructure development (ideally both), we want to talk to you.</p><p style=\"min-height:1.5em\"><strong>Ready to help shape the future of AI?</strong> Apply now and join us in our mission to make powerful AI models accessible to everyone.</p>", "descriptionPlain": "BUILDING THE FUTURE OF DECENTRALIZED AI DEVELOPMENT\n\nPrime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.\n\nWe recently raised $15mm in funding https://www.primeintellect.ai/blog/fundraise (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.\n\n\nROLE IMPACT\n\nThis is a hybrid role spanning both our developer platform and infrastructure layers. You'll work on two key areas:\n\n1. Our developer-facing platform for AI workload management\n\n2. The underlying distributed infrastructure that powers our training systems\n\n\nCORE TECHNICAL RESPONSIBILITIES\n\nPlatform Development\n\n- Build intuitive web interfaces for AI workload management and monitoring\n\n- Develop REST APIs and backend services in Python\n\n- Create real-time monitoring and debugging tools\n\n- Implement user-facing features for resource management and job control\n\nInfrastructure Development\n\n- Design and implement distributed training infrastructure in Rust\n\n- Build high-performance networking and coordination components\n\n- Create infrastructure automation pipelines with Ansible\n\n- Manage cloud resources and container orchestration\n\n- Implement scheduling systems for heterogeneous hardware (CPU, GPU, TPU)\n\n\nTECHNICAL REQUIREMENTS\n\nPlatform Skills\n\n- Strong Python backend development (FastAPI, async)\n\n- Modern frontend development (TypeScript, React/Next.js, Tailwind)\n\n- Experience building developer tools and dashboards\n\n- RESTful API design and implementation\n\nInfrastructure Skills\n\n- Systems programming experience with Rust\n\n- Infrastructure automation (Ansible, Terraform)\n\n- Container orchestration (Kubernetes)\n\n- Cloud platform expertise (GCP preferred)\n\n- Observability tools (Prometheus, Grafana)\n\n\nNICE TO HAVE\n\n- Experience with GPU computing and ML infrastructure\n\n- Knowledge of AI/ML model architecture and training\n\n- High-performance networking implementation\n\n- Open-source infrastructure contributions\n\n- WebSocket/real-time systems experience\n\n\nWHAT WE OFFER\n\n- Competitive compensation with significant equity incentives\n\n- Flexible work arrangement (remote or San Francisco office)\n\n- Full visa sponsorship and relocation support\n\n- Professional development budget for courses and conferences\n\n- Regular team off-sites and conference attendance\n\n- Opportunity to shape the future of decentralized AI development\n\n\nGROWTH OPPORTUNITY\n\nYou'll join a team of experienced engineers and researchers working on cutting-edge problems in AI infrastructure. We believe in open development and encourage team members to contribute to the broader AI community through research and open-source contributions.\n\nWe value potential over perfection - if you're passionate about democratizing AI development and have experience in either platform or infrastructure development (ideally both), we want to talk to you.\n\nReady to help shape the future of AI? Apply now and join us in our mission to make powerful AI models accessible to everyone.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "4c6ccfd6-6512-4905-979a-6dcc6d64a935", "title": "Head of Growth", "department": "Operations", "team": "Operations", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [], "publishedAt": "2025-10-13T23:42:05.435+00:00", "isListed": true, "isRemote": false, "address": {"postalAddress": {"addressRegion": "California", "addressCountry": "United States", "addressLocality": "San Francisco"}}, "jobUrl": "https://jobs.ashbyhq.com/PrimeIntellect/4c6ccfd6-6512-4905-979a-6dcc6d64a935", "applyUrl": "https://jobs.ashbyhq.com/PrimeIntellect/4c6ccfd6-6512-4905-979a-6dcc6d64a935/application", "descriptionHtml": "<p style=\"min-height:1.5em\"><strong>Building Open Superintelligence Infrastructure</strong><br />Prime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.</p><p style=\"min-height:1.5em\">We recently raised <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.primeintellect.ai/blog/fundraise\">$15mm in funding</a> (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.</p><p style=\"min-height:1.5em\"></p><h2><strong>Your Role</strong></h2><p style=\"min-height:1.5em\">As <strong>Head of Growth</strong>, you\u2019ll lead everything that connects our technology to the market \u2014 spanning sales, marketing, partnerships, and customer success. You\u2019ll define how Prime Intellect tells its story, close large-scale post-training and compute contracts, and build the systems that let us scale revenue efficiently. This is a high-leverage role combining strategy, execution, and team building \u2014 perfect for a hybrid commercial operator who thrives at the intersection of infrastructure and intelligence.</p><p style=\"min-height:1.5em\"></p><h2><strong>Responsibilities</strong></h2><p style=\"min-height:1.5em\"><strong>Strategy &amp; Vision</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Build and lead a cross-functional Growth organization spanning Sales, Marketing, Partnerships, and Customer Success.</p></li><li><p style=\"min-height:1.5em\">Define our go-to-market strategy for RL infrastructure pricing, packaging, and positioning.</p></li><li><p style=\"min-height:1.5em\">Own revenue forecasting, pipeline visibility, and operational cadence (CRM, dashboards, and forecasting systems).</p></li><li><p style=\"min-height:1.5em\">Design data-driven systems for deal tracking, reporting, and forecasting accuracy.</p></li></ul><p style=\"min-height:1.5em\"><strong>Sales &amp; Partnerships</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Lead enterprise sales cycles for post-training and multi-node cluster deals (64+ GPUs, 6+ month durations).</p></li><li><p style=\"min-height:1.5em\">Develop repeatable playbooks for design-partner conversions and enterprise onboarding.</p></li><li><p style=\"min-height:1.5em\">Build strategic partnerships with compute providers, AI companies, and research labs to expand our ecosystem.</p></li><li><p style=\"min-height:1.5em\">Identify and nurture high-value leads through targeted outbound and inbound growth strategies.</p></li></ul><p style=\"min-height:1.5em\"><strong>Marketing</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Drive developer and enterprise awareness through campaigns, launches, community, and content.</p></li><li><p style=\"min-height:1.5em\">Translate technical features into clear market narratives and differentiated positioning.</p></li><li><p style=\"min-height:1.5em\">Partner with Product to align market feedback with roadmap and developer onboarding.</p></li><li><p style=\"min-height:1.5em\">Run quantitative experiments on activation, conversion, and usage metrics.</p></li></ul><p style=\"min-height:1.5em\"><strong>Customer Success / Account Management</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Build the CS motion across onboarding, usage analytics, renewals, and expansion workflows.</p></li><li><p style=\"min-height:1.5em\">Implement CRM-based renewal tracking and feedback loops into product and operations.</p></li><li><p style=\"min-height:1.5em\">Establish systems for continuous measurement of customer value and satisfaction.</p></li></ul><p style=\"min-height:1.5em\"><strong>Growth Operations</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Design scalable processes for deal management, supplier bidding, contract ops, and revenue tracking.</p></li><li><p style=\"min-height:1.5em\">Partner with Operations and Finance on budgeting, hiring, and legal structures that support rapid scale.</p></li><li><p style=\"min-height:1.5em\">Implement sales technology stack and CRM architecture to enable data-driven decision making.</p></li></ul><h3><strong>What We\u2019re Looking For</strong></h3><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">5+ years leading growth, GTM, or revenue functions at a B2B or infrastructure startup.</p></li><li><p style=\"min-height:1.5em\">Fluent in both technical and commercial conversations \u2014 comfortable discussing GPUs, APIs, and pricing models.</p></li><li><p style=\"min-height:1.5em\">Proven ability to build scalable systems (CRM, forecasting, dashboards) and clean operational processes.</p></li><li><p style=\"min-height:1.5em\">Track record of closing enterprise-scale infrastructure or developer-tooling deals.</p></li><li><p style=\"min-height:1.5em\">Analytical, curious, and comfortable in high-ambiguity, fast-moving environments.</p></li><li><p style=\"min-height:1.5em\">Strong communication and leadership skills with experience building small, high-performing teams.</p></li></ul><p style=\"min-height:1.5em\"><strong>Bonus:</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Experience pricing or selling infrastructure or developer tools.</p></li><li><p style=\"min-height:1.5em\">Familiarity with enterprise AI, cloud infrastructure, or post-training markets.</p></li><li><p style=\"min-height:1.5em\">Early-stage operator mindset \u2014 bias for building playbooks, not inheriting them.</p></li></ul><p style=\"min-height:1.5em\"></p><h2>What We Offer</h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\"><strong>Competitive Compensation</strong> + equity incentives</p></li><li><p style=\"min-height:1.5em\"><strong>Flexible Work</strong> (remote or San Francisco)</p></li><li><p style=\"min-height:1.5em\"><strong>Visa Sponsorship</strong> &amp; relocation support</p></li><li><p style=\"min-height:1.5em\"><strong>Professional Development</strong> budget</p></li><li><p style=\"min-height:1.5em\"><strong>Team Off-sites</strong> &amp; conference attendance</p></li><li><p style=\"min-height:1.5em\"><strong>Opportunity to Shape Decentralized AI</strong> at Prime Intellect</p></li></ul>", "descriptionPlain": "Building Open Superintelligence Infrastructure\nPrime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.\n\nWe recently raised $15mm in funding https://www.primeintellect.ai/blog/fundraise (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.\n\n\nYOUR ROLE\n\nAs Head of Growth, you\u2019ll lead everything that connects our technology to the market \u2014 spanning sales, marketing, partnerships, and customer success. You\u2019ll define how Prime Intellect tells its story, close large-scale post-training and compute contracts, and build the systems that let us scale revenue efficiently. This is a high-leverage role combining strategy, execution, and team building \u2014 perfect for a hybrid commercial operator who thrives at the intersection of infrastructure and intelligence.\n\n\nRESPONSIBILITIES\n\nStrategy & Vision\n\n - Build and lead a cross-functional Growth organization spanning Sales, Marketing, Partnerships, and Customer Success.\n\n - Define our go-to-market strategy for RL infrastructure pricing, packaging, and positioning.\n\n - Own revenue forecasting, pipeline visibility, and operational cadence (CRM, dashboards, and forecasting systems).\n\n - Design data-driven systems for deal tracking, reporting, and forecasting accuracy.\n\nSales & Partnerships\n\n - Lead enterprise sales cycles for post-training and multi-node cluster deals (64+ GPUs, 6+ month durations).\n\n - Develop repeatable playbooks for design-partner conversions and enterprise onboarding.\n\n - Build strategic partnerships with compute providers, AI companies, and research labs to expand our ecosystem.\n\n - Identify and nurture high-value leads through targeted outbound and inbound growth strategies.\n\nMarketing\n\n - Drive developer and enterprise awareness through campaigns, launches, community, and content.\n\n - Translate technical features into clear market narratives and differentiated positioning.\n\n - Partner with Product to align market feedback with roadmap and developer onboarding.\n\n - Run quantitative experiments on activation, conversion, and usage metrics.\n\nCustomer Success / Account Management\n\n - Build the CS motion across onboarding, usage analytics, renewals, and expansion workflows.\n\n - Implement CRM-based renewal tracking and feedback loops into product and operations.\n\n - Establish systems for continuous measurement of customer value and satisfaction.\n\nGrowth Operations\n\n - Design scalable processes for deal management, supplier bidding, contract ops, and revenue tracking.\n\n - Partner with Operations and Finance on budgeting, hiring, and legal structures that support rapid scale.\n\n - Implement sales technology stack and CRM architecture to enable data-driven decision making.\n\n\nWHAT WE\u2019RE LOOKING FOR\n\n - 5+ years leading growth, GTM, or revenue functions at a B2B or infrastructure startup.\n\n - Fluent in both technical and commercial conversations \u2014 comfortable discussing GPUs, APIs, and pricing models.\n\n - Proven ability to build scalable systems (CRM, forecasting, dashboards) and clean operational processes.\n\n - Track record of closing enterprise-scale infrastructure or developer-tooling deals.\n\n - Analytical, curious, and comfortable in high-ambiguity, fast-moving environments.\n\n - Strong communication and leadership skills with experience building small, high-performing teams.\n\nBonus:\n\n - Experience pricing or selling infrastructure or developer tools.\n\n - Familiarity with enterprise AI, cloud infrastructure, or post-training markets.\n\n - Early-stage operator mindset \u2014 bias for building playbooks, not inheriting them.\n\n\nWHAT WE OFFER\n\n - Competitive Compensation + equity incentives\n\n - Flexible Work (remote or San Francisco)\n\n - Visa Sponsorship & relocation support\n\n - Professional Development budget\n\n - Team Off-sites & conference attendance\n\n - Opportunity to Shape Decentralized AI at Prime Intellect", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "afa6079a-5a35-4f90-ba88-780e4d36112f", "title": "AI Research Resident - Open Source AGI", "department": "Research", "team": "Research", "employmentType": "FullTime", "location": "Remote", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [], "publishedAt": "2024-04-11T19:29:23.063+00:00", "isListed": true, "isRemote": true, "address": {"postalAddress": {"addressCountry": "United States"}}, "jobUrl": "https://jobs.ashbyhq.com/PrimeIntellect/afa6079a-5a35-4f90-ba88-780e4d36112f", "applyUrl": "https://jobs.ashbyhq.com/PrimeIntellect/afa6079a-5a35-4f90-ba88-780e4d36112f/application", "descriptionHtml": "<h2><strong>Overview</strong></h2><p style=\"min-height:1.5em\">Prime Intellect is excited to announce our AI Research Residency Program, a unique opportunity for exceptional researchers, engineers, and hackers to join our team for 3-12 months and contribute to state-of-the-art decentralized AI research project. This program is designed to provide a bridge for brilliant technical minds from diverse fields to transition into AI research and development.</p><p style=\"min-height:1.5em\"></p><h2><strong>About Prime Intellect</strong></h2><p style=\"min-height:1.5em\">At Prime Intellect, we are on a mission to accelerate open and decentralized AI progress by enabling anyone to contribute compute, code or capital to train powerful, open models. Our ultimate goal? Openly accessible AGI that benefits everyone.</p><p style=\"min-height:1.5em\">We are building the infrastructure for decentralized AI development at scale. We aggregate global compute and enable researchers to collaboratively train state-of-the-art models through distributed training across clusters..</p><p style=\"min-height:1.5em\"></p><h2><strong>About the Program</strong></h2><p style=\"min-height:1.5em\">The Prime Intellect AI Research Residency is a paid, full-time program that offers hands-on experience working on real-world AI challenges alongside our world-class research team. Residents will have the opportunity to:</p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Collaborate with leading experts in AI, distributed systems, and protocols to develop state-of-the-art open language models, coding agents, and scientific discovery models</p></li><li><p style=\"min-height:1.5em\">Contribute to projects focused on democratizing AI and making it universally accessible through the Prime Intellect platform</p></li><li><p style=\"min-height:1.5em\">Gain practical experience in developing and deploying large-scale AI models using novel architectures and distributed training techniques across thousands of GPUs and smaller clusters</p></li><li><p style=\"min-height:1.5em\">Publish research papers and present findings at top-tier AI conferences</p></li><li><p style=\"min-height:1.5em\">Develop a strong network within the decentralized AI community</p></li></ul><p style=\"min-height:1.5em\"></p><h2><strong>Who We're Looking For</strong></h2><p style=\"min-height:1.5em\">We welcome applications from researchers, engineers, and hackers with diverse backgrounds and skill sets, including but not limited to:</p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">PhD students or postdoctoral researchers in computer science, mathematics, physics, neuroscience, or related fields</p></li><li><p style=\"min-height:1.5em\">Experienced software engineers with a strong interest in transitioning to AI research</p></li><li><p style=\"min-height:1.5em\">Self-taught individuals with a proven track record of exceptional technical contributions</p></li><li><p style=\"min-height:1.5em\">Candidates with experience in machine learning, distributed systems, or protocols</p></li></ul><p style=\"min-height:1.5em\"></p><h2><strong>Focus Areas</strong></h2><p style=\"min-height:1.5em\">Residents will have the opportunity to work on one or more of the following focus areas:</p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\"><strong>Distributed AI Infrastructure</strong>: Contribute to the development of the Prime Intellect protocol, enabling massively scalable, distributed compute marketplaces and collective ownership of AI models.</p></li><li><p style=\"min-height:1.5em\"><strong>Open Language Models</strong>: Build large language models like open-source software, allowing for continual improvement and model merging. We envision a future where all training compute can be built upon by everyone so that all efforts towards intelligence are cumulative. (<a target=\"_blank\" rel=\"noopener noreferrer\" class=\"notion-link-token notion-focusable-token notion-enable-hover\" href=\"https://colinraffel.com/blog/a-call-to-build-models-like-we-build-open-source-software.html\">Inspired by Colin Raffel</a>).</p></li><li><p style=\"min-height:1.5em\"><strong>Coding Agents</strong>: Train AI agents that deeply understand code semantics and can autonomously build complex software systems.</p></li><li><p style=\"min-height:1.5em\"><strong>Scientific Discovery</strong>: Explore scientific agents and foundation models to accelerate research in fields such as longevity drug discovery, materials science and other scientific areas.</p></li></ul><p style=\"min-height:1.5em\"></p><h2><strong>Benefits &amp; Perks</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Competitive compensation, including equity incentives, aligning your success with the growth and impact of Prime Intellect.</p></li><li><p style=\"min-height:1.5em\">Flexible work arrangements, with the option to work remotely or in-person at our offices in San Francisco or Berlin.</p></li><li><p style=\"min-height:1.5em\">Visa sponsorship and relocation assistance for international candidates.</p></li><li><p style=\"min-height:1.5em\">Quarterly team off-sites, hackathons, conferences and learning opportunities.</p></li><li><p style=\"min-height:1.5em\">Opportunity to work with a talented, hard-working and mission-driven team, united by a shared passion for leveraging technology to accelerate science and AI.</p></li></ul><p style=\"min-height:1.5em\">We recently raised <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.primeintellect.ai/blog/fundraise\">$15mm in funding</a> (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.</p><p style=\"min-height:1.5em\">If you're excited about the opportunity to build the foundation for the future of decentralized AI and create a platform that empowers developers and researchers to push the boundaries of what's possible, we'd love to hear from you.</p>", "descriptionPlain": "OVERVIEW\n\nPrime Intellect is excited to announce our AI Research Residency Program, a unique opportunity for exceptional researchers, engineers, and hackers to join our team for 3-12 months and contribute to state-of-the-art decentralized AI research project. This program is designed to provide a bridge for brilliant technical minds from diverse fields to transition into AI research and development.\n\n\nABOUT PRIME INTELLECT\n\nAt Prime Intellect, we are on a mission to accelerate open and decentralized AI progress by enabling anyone to contribute compute, code or capital to train powerful, open models. Our ultimate goal? Openly accessible AGI that benefits everyone.\n\nWe are building the infrastructure for decentralized AI development at scale. We aggregate global compute and enable researchers to collaboratively train state-of-the-art models through distributed training across clusters..\n\n\nABOUT THE PROGRAM\n\nThe Prime Intellect AI Research Residency is a paid, full-time program that offers hands-on experience working on real-world AI challenges alongside our world-class research team. Residents will have the opportunity to:\n\n - Collaborate with leading experts in AI, distributed systems, and protocols to develop state-of-the-art open language models, coding agents, and scientific discovery models\n\n - Contribute to projects focused on democratizing AI and making it universally accessible through the Prime Intellect platform\n\n - Gain practical experience in developing and deploying large-scale AI models using novel architectures and distributed training techniques across thousands of GPUs and smaller clusters\n\n - Publish research papers and present findings at top-tier AI conferences\n\n - Develop a strong network within the decentralized AI community\n\n\nWHO WE'RE LOOKING FOR\n\nWe welcome applications from researchers, engineers, and hackers with diverse backgrounds and skill sets, including but not limited to:\n\n - PhD students or postdoctoral researchers in computer science, mathematics, physics, neuroscience, or related fields\n\n - Experienced software engineers with a strong interest in transitioning to AI research\n\n - Self-taught individuals with a proven track record of exceptional technical contributions\n\n - Candidates with experience in machine learning, distributed systems, or protocols\n\n\nFOCUS AREAS\n\nResidents will have the opportunity to work on one or more of the following focus areas:\n\n - Distributed AI Infrastructure: Contribute to the development of the Prime Intellect protocol, enabling massively scalable, distributed compute marketplaces and collective ownership of AI models.\n\n - Open Language Models: Build large language models like open-source software, allowing for continual improvement and model merging. We envision a future where all training compute can be built upon by everyone so that all efforts towards intelligence are cumulative. (Inspired by Colin Raffel https://colinraffel.com/blog/a-call-to-build-models-like-we-build-open-source-software.html).\n\n - Coding Agents: Train AI agents that deeply understand code semantics and can autonomously build complex software systems.\n\n - Scientific Discovery: Explore scientific agents and foundation models to accelerate research in fields such as longevity drug discovery, materials science and other scientific areas.\n\n\nBENEFITS & PERKS\n\n - Competitive compensation, including equity incentives, aligning your success with the growth and impact of Prime Intellect.\n\n - Flexible work arrangements, with the option to work remotely or in-person at our offices in San Francisco or Berlin.\n\n - Visa sponsorship and relocation assistance for international candidates.\n\n - Quarterly team off-sites, hackathons, conferences and learning opportunities.\n\n - Opportunity to work with a talented, hard-working and mission-driven team, united by a shared passion for leveraging technology to accelerate science and AI.\n\nWe recently raised $15mm in funding https://www.primeintellect.ai/blog/fundraise (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.\n\nIf you're excited about the opportunity to build the foundation for the future of decentralized AI and create a platform that empowers developers and researchers to push the boundaries of what's possible, we'd love to hear from you.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "3428298f-63db-40ab-b70b-a5583e8ddea1", "title": "Member of Technical Staff - Agents", "department": "Engineering", "team": "Engineering", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [], "publishedAt": "2025-01-10T03:42:31.203+00:00", "isListed": true, "isRemote": false, "address": {"postalAddress": {"addressRegion": "California", "addressCountry": "United States", "addressLocality": "San Francisco"}}, "jobUrl": "https://jobs.ashbyhq.com/PrimeIntellect/3428298f-63db-40ab-b70b-a5583e8ddea1", "applyUrl": "https://jobs.ashbyhq.com/PrimeIntellect/3428298f-63db-40ab-b70b-a5583e8ddea1/application", "descriptionHtml": "<p style=\"min-height:1.5em\"><strong>Building the Future of Open Source + Decentralized AI </strong><br />Prime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.</p><p style=\"min-height:1.5em\">We recently raised <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.primeintellect.ai/blog/fundraise\">$15mm in funding</a> (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.</p><h3><br />Role Impact</h3><p style=\"min-height:1.5em\">This is a hybrid position spanning the quick and iterative development of <strong>AI agents and frameworks</strong> and advancing the underlying<strong> infrastructure</strong>. You\u2019ll focus on:</p><ol style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\"><strong>Building the next-generation AI agents</strong> to handle workload management and automation.</p></li><li><p style=\"min-height:1.5em\"><strong>Building out the underlying agent infrastructure</strong> that power different kinds of agents.</p></li><li><p style=\"min-height:1.5em\"><strong>DevRel + Content: </strong>Create technical content to drive adoption, engage communities for collaboration and feedback, and coordinate across teams to align technical and product goals.</p></li></ol><h2><br />Core Technical Responsibilities</h2><h3>Rapid AI Agent Development</h3><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\"><strong>Prototype &amp; Iterate</strong>: Build and refine AI agents for workload management, automation, and real-time decision-making.</p></li><li><p style=\"min-height:1.5em\"><strong>Framework Integration</strong>: Contribute to and extend agent frameworks to handle evolving feature requests and performance needs.</p></li><li><p style=\"min-height:1.5em\"><strong>Experimental Features</strong>: Quickly explore new agent capabilities (e.g., multi-agent collaboration, memory architectures) to guide design choices.</p></li></ul><h3>Agent Infrastructure &amp; Backbones</h3><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\"><strong>Scalable Deployments</strong>: Architect and maintain systems that support distributed AI agent execution at scale.</p></li><li><p style=\"min-height:1.5em\"><strong>Networking &amp; Coordination</strong>: Implement robust protocols for data exchange and coordination across distributed agents.</p></li><li><p style=\"min-height:1.5em\"><strong>System Observability</strong>: Leverage monitoring tools (Prometheus, Grafana) to track agent performance and resource utilization.</p></li><li><p style=\"min-height:1.5em\"><strong>Resource Orchestration</strong>: Manage containerized environments (Kubernetes, Docker) and automate infrastructure (Terraform, Ansible) for seamless agent operations.</p></li></ul><h3>Collaboration &amp; Community Engagement</h3><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\"><strong>Cross-Team Alignment</strong>: Work closely with product, research, and other engineering teams to identify key improvements and ensure agent features match real-world needs.</p></li><li><p style=\"min-height:1.5em\"><strong>DevRel &amp; Content</strong>: Produce clear technical documentation, guides, and demos, driving open-source adoption and helping new users onboard quickly.</p></li><li><p style=\"min-height:1.5em\"><strong>Open-Source Contributions</strong>: Engage with the community by pushing code, merging pull requests, and resolving issues, championing decentralized AI best practices.</p></li></ul><h2>Technical Requirements</h2><h3>Agent &amp; Platform Skills</h3><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\"><strong>Python (FastAPI, Async)</strong>: Proficiency in building agent logic, REST APIs, and backend services.</p></li><li><p style=\"min-height:1.5em\"><strong>Pytorch</strong></p></li><li><p style=\"min-height:1.5em\"><strong>TypeScript/React/Next.js</strong>: Comfortable creating dashboards or other visualizations for agent monitoring.</p></li><li><p style=\"min-height:1.5em\"><strong>Real-time &amp; WebSocket Systems</strong>: Experience building streaming or live-updating UIs to visualize agent activity.</p></li><li><p style=\"min-height:1.5em\"><strong>API Design</strong>: Ability to craft intuitive and efficient interfaces for agent communication.</p></li></ul><h3>Infrastructure Skills</h3><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\"><strong>Rust</strong>: Systems programming for high-performance agent components.</p></li><li><p style=\"min-height:1.5em\"><strong>Kubernetes, Docker</strong>: Container orchestration and production-ready deployments.</p></li><li><p style=\"min-height:1.5em\">Infrastructure automation and config management.</p></li><li><p style=\"min-height:1.5em\"><strong>Cloud Experience</strong>: Familiarity with scalable and cost-effective infrastructure.</p></li></ul><h3>Nice to Have</h3><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\"><strong>GPU/ML Infrastructure</strong>: Understanding how to optimize agent training or inference on GPUs.</p></li><li><p style=\"min-height:1.5em\"><strong>Advanced AI/ML Knowledge</strong>: Familiarity with popular model architectures and training workflows.</p></li><li><p style=\"min-height:1.5em\"><strong>High-Performance Networking</strong>: Experience building low-latency data pipelines.</p></li><li><p style=\"min-height:1.5em\"><strong>Open-Source Contributions</strong>: Proven track record in community-driven projects.</p></li></ul><h2>What We Offer</h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\"><strong>Competitive Compensation</strong> + equity incentives</p></li><li><p style=\"min-height:1.5em\"><strong>Flexible Work</strong> (remote or San Francisco)</p></li><li><p style=\"min-height:1.5em\"><strong>Visa Sponsorship</strong> &amp; relocation support</p></li><li><p style=\"min-height:1.5em\"><strong>Professional Development</strong> budget</p></li><li><p style=\"min-height:1.5em\"><strong>Team Off-sites</strong> &amp; conference attendance</p></li><li><p style=\"min-height:1.5em\"><strong>Opportunity to Shape Decentralized AI</strong> at Prime Intellect</p></li></ul><h2><br />Growth Opportunity</h2><p style=\"min-height:1.5em\">You\u2019ll work with an expert, mission-driven team tackling the complexities of open, decentralized AI. If you\u2019re passionate about agent-driven solutions and thrive in fast, iterative development, we\u2019d love to hear from you.<br /></p><p style=\"min-height:1.5em\"><strong>Ready to build the AI agent system of tomorrow?</strong><br />Apply now to help us make powerful, open AGI accessible to everyone.</p>", "descriptionPlain": "Building the Future of Open Source + Decentralized AI\nPrime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.\n\nWe recently raised $15mm in funding https://www.primeintellect.ai/blog/fundraise (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.\n\n\n\nROLE IMPACT\n\nThis is a hybrid position spanning the quick and iterative development of AI agents and frameworks and advancing the underlying infrastructure. You\u2019ll focus on:\n\n 1. Building the next-generation AI agents to handle workload management and automation.\n\n 2. Building out the underlying agent infrastructure that power different kinds of agents.\n\n 3. DevRel + Content: Create technical content to drive adoption, engage communities for collaboration and feedback, and coordinate across teams to align technical and product goals.\n\n\n\nCORE TECHNICAL RESPONSIBILITIES\n\n\nRAPID AI AGENT DEVELOPMENT\n\n - Prototype & Iterate: Build and refine AI agents for workload management, automation, and real-time decision-making.\n\n - Framework Integration: Contribute to and extend agent frameworks to handle evolving feature requests and performance needs.\n\n - Experimental Features: Quickly explore new agent capabilities (e.g., multi-agent collaboration, memory architectures) to guide design choices.\n\n\nAGENT INFRASTRUCTURE & BACKBONES\n\n - Scalable Deployments: Architect and maintain systems that support distributed AI agent execution at scale.\n\n - Networking & Coordination: Implement robust protocols for data exchange and coordination across distributed agents.\n\n - System Observability: Leverage monitoring tools (Prometheus, Grafana) to track agent performance and resource utilization.\n\n - Resource Orchestration: Manage containerized environments (Kubernetes, Docker) and automate infrastructure (Terraform, Ansible) for seamless agent operations.\n\n\nCOLLABORATION & COMMUNITY ENGAGEMENT\n\n - Cross-Team Alignment: Work closely with product, research, and other engineering teams to identify key improvements and ensure agent features match real-world needs.\n\n - DevRel & Content: Produce clear technical documentation, guides, and demos, driving open-source adoption and helping new users onboard quickly.\n\n - Open-Source Contributions: Engage with the community by pushing code, merging pull requests, and resolving issues, championing decentralized AI best practices.\n\n\nTECHNICAL REQUIREMENTS\n\n\nAGENT & PLATFORM SKILLS\n\n - Python (FastAPI, Async): Proficiency in building agent logic, REST APIs, and backend services.\n\n - Pytorch\n\n - TypeScript/React/Next.js: Comfortable creating dashboards or other visualizations for agent monitoring.\n\n - Real-time & WebSocket Systems: Experience building streaming or live-updating UIs to visualize agent activity.\n\n - API Design: Ability to craft intuitive and efficient interfaces for agent communication.\n\n\nINFRASTRUCTURE SKILLS\n\n - Rust: Systems programming for high-performance agent components.\n\n - Kubernetes, Docker: Container orchestration and production-ready deployments.\n\n - Infrastructure automation and config management.\n\n - Cloud Experience: Familiarity with scalable and cost-effective infrastructure.\n\n\nNICE TO HAVE\n\n - GPU/ML Infrastructure: Understanding how to optimize agent training or inference on GPUs.\n\n - Advanced AI/ML Knowledge: Familiarity with popular model architectures and training workflows.\n\n - High-Performance Networking: Experience building low-latency data pipelines.\n\n - Open-Source Contributions: Proven track record in community-driven projects.\n\n\nWHAT WE OFFER\n\n - Competitive Compensation + equity incentives\n\n - Flexible Work (remote or San Francisco)\n\n - Visa Sponsorship & relocation support\n\n - Professional Development budget\n\n - Team Off-sites & conference attendance\n\n - Opportunity to Shape Decentralized AI at Prime Intellect\n\n\n\nGROWTH OPPORTUNITY\n\nYou\u2019ll work with an expert, mission-driven team tackling the complexities of open, decentralized AI. If you\u2019re passionate about agent-driven solutions and thrive in fast, iterative development, we\u2019d love to hear from you.\n\n\nReady to build the AI agent system of tomorrow?\nApply now to help us make powerful, open AGI accessible to everyone.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "297d925e-5a42-40bd-b02f-5c928d226f18", "title": "Member of Technical Staff - GPU Infrastructure", "department": "Engineering", "team": "Engineering", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [{"location": "Remote", "address": {"postalAddress": {"addressCountry": "United States"}}}], "publishedAt": "2025-08-30T02:04:27.300+00:00", "isListed": true, "isRemote": false, "address": {"postalAddress": {"addressRegion": "California", "addressCountry": "United States", "addressLocality": "San Francisco"}}, "jobUrl": "https://jobs.ashbyhq.com/PrimeIntellect/297d925e-5a42-40bd-b02f-5c928d226f18", "applyUrl": "https://jobs.ashbyhq.com/PrimeIntellect/297d925e-5a42-40bd-b02f-5c928d226f18/application", "descriptionHtml": "<h1><strong>Building the Future of Decentralized AI Development</strong></h1><p style=\"min-height:1.5em\">Prime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.</p><p style=\"min-height:1.5em\">As our Solutions Architect for GPU Infrastructure, you'll be the technical expert who transforms customer requirements into production-ready systems capable of training the world's most advanced AI models.</p><p style=\"min-height:1.5em\">We recently raised $15mm in funding (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.</p><p style=\"min-height:1.5em\"></p><p style=\"min-height:1.5em\"><strong>Core Technical Responsibilities</strong></p><p style=\"min-height:1.5em\">This customer-facing role combines deep technical expertise with hands-on implementation. You'll be instrumental in:</p><p style=\"min-height:1.5em\"><strong>Customer Architecture &amp; Design</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Partner with clients to understand workload requirements and design optimal GPU cluster architectures</p></li><li><p style=\"min-height:1.5em\">Create technical proposals and capacity planning for clusters ranging from 100 to 10,000+ GPUs</p></li><li><p style=\"min-height:1.5em\">Develop deployment strategies for LLM training, inference, and HPC workloads</p></li><li><p style=\"min-height:1.5em\">Present architectural recommendations to technical and executive stakeholders</p></li></ul><p style=\"min-height:1.5em\"><strong>Infrastructure Deployment &amp; Optimization</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Deploy and configure orchestration systems including SLURM and Kubernetes for distributed workloads</p></li><li><p style=\"min-height:1.5em\">Implement high-performance networking with InfiniBand, RoCE, and NVLink interconnects</p></li><li><p style=\"min-height:1.5em\">Optimize GPU utilization, memory management, and inter-node communication</p></li><li><p style=\"min-height:1.5em\">Configure parallel filesystems (Lustre, BeeGFS, GPFS) for optimal I/O performance</p></li><li><p style=\"min-height:1.5em\">Tune system performance from kernel parameters to CUDA configurations</p></li></ul><p style=\"min-height:1.5em\"><strong>Production Operations &amp; Support</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Serve as primary technical escalation point for customer infrastructure issues</p></li><li><p style=\"min-height:1.5em\">Diagnose and resolve complex problems across the full stack - hardware, drivers, networking, and software</p></li><li><p style=\"min-height:1.5em\">Implement monitoring, alerting, and automated remediation systems</p></li><li><p style=\"min-height:1.5em\">Provide 24/7 on-call support for critical customer deployments</p></li><li><p style=\"min-height:1.5em\">Create runbooks and documentation for customer operations teams</p></li></ul><p style=\"min-height:1.5em\"><strong>Technical Requirements</strong></p><p style=\"min-height:1.5em\"><strong>Required Experience</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">3+ years hands-on experience with GPU clusters and HPC environments</p></li><li><p style=\"min-height:1.5em\">Deep expertise with SLURM and Kubernetes in production GPU settings</p></li><li><p style=\"min-height:1.5em\">Proven experience with InfiniBand configuration and troubleshooting</p></li><li><p style=\"min-height:1.5em\">Strong understanding of NVIDIA GPU architecture, CUDA ecosystem, and driver stack</p></li><li><p style=\"min-height:1.5em\">Experience with infrastructure automation tools (Ansible, Terraform)</p></li><li><p style=\"min-height:1.5em\">Proficiency in Python, Bash, and systems programming</p></li><li><p style=\"min-height:1.5em\">Track record of customer-facing technical leadership</p></li></ul><p style=\"min-height:1.5em\"><strong>Infrastructure Skills</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">NVIDIA driver installation and troubleshooting (CUDA, Fabric Manager, DCGM)</p></li><li><p style=\"min-height:1.5em\">Container runtime configuration for GPUs (Docker, Containerd, Enroot)</p></li><li><p style=\"min-height:1.5em\">Linux kernel tuning and performance optimization</p></li><li><p style=\"min-height:1.5em\">Network topology design for AI workloads</p></li><li><p style=\"min-height:1.5em\">Power and cooling requirements for high-density GPU deployments</p></li></ul><p style=\"min-height:1.5em\"><strong>Nice to Have</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Experience with 1000+ GPU deployments</p></li><li><p style=\"min-height:1.5em\">NVIDIA DGX, HGX, or SuperPOD certification</p></li><li><p style=\"min-height:1.5em\">Distributed training frameworks (PyTorch FSDP, DeepSpeed, Megatron-LM)</p></li><li><p style=\"min-height:1.5em\">ML framework optimization and profiling</p></li><li><p style=\"min-height:1.5em\">Experience with AMD MI300 or Intel Gaudi accelerators</p></li><li><p style=\"min-height:1.5em\">Contributions to open-source HPC/AI infrastructure projects</p></li></ul><p style=\"min-height:1.5em\"><strong>Growth Opportunity</strong></p><p style=\"min-height:1.5em\">You'll work directly with customers pushing the boundaries of AI, from startups training foundation models to enterprises deploying massive inference infrastructure. You'll collaborate with our world-class engineering team while having direct impact on systems powering the next generation of AI breakthroughs.</p><p style=\"min-height:1.5em\">We value expertise and customer obsession - if you're passionate about building reliable, high-performance GPU infrastructure and have a track record of successful large-scale deployments, we want to talk to you.</p><p style=\"min-height:1.5em\">Apply now and join us in our mission to democratize access to planetary scale computing.</p><p style=\"min-height:1.5em\"></p>", "descriptionPlain": "BUILDING THE FUTURE OF DECENTRALIZED AI DEVELOPMENT\n\nPrime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.\n\nAs our Solutions Architect for GPU Infrastructure, you'll be the technical expert who transforms customer requirements into production-ready systems capable of training the world's most advanced AI models.\n\nWe recently raised $15mm in funding (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.\n\nCore Technical Responsibilities\n\nThis customer-facing role combines deep technical expertise with hands-on implementation. You'll be instrumental in:\n\nCustomer Architecture & Design\n\n - Partner with clients to understand workload requirements and design optimal GPU cluster architectures\n\n - Create technical proposals and capacity planning for clusters ranging from 100 to 10,000+ GPUs\n\n - Develop deployment strategies for LLM training, inference, and HPC workloads\n\n - Present architectural recommendations to technical and executive stakeholders\n\nInfrastructure Deployment & Optimization\n\n - Deploy and configure orchestration systems including SLURM and Kubernetes for distributed workloads\n\n - Implement high-performance networking with InfiniBand, RoCE, and NVLink interconnects\n\n - Optimize GPU utilization, memory management, and inter-node communication\n\n - Configure parallel filesystems (Lustre, BeeGFS, GPFS) for optimal I/O performance\n\n - Tune system performance from kernel parameters to CUDA configurations\n\nProduction Operations & Support\n\n - Serve as primary technical escalation point for customer infrastructure issues\n\n - Diagnose and resolve complex problems across the full stack - hardware, drivers, networking, and software\n\n - Implement monitoring, alerting, and automated remediation systems\n\n - Provide 24/7 on-call support for critical customer deployments\n\n - Create runbooks and documentation for customer operations teams\n\nTechnical Requirements\n\nRequired Experience\n\n - 3+ years hands-on experience with GPU clusters and HPC environments\n\n - Deep expertise with SLURM and Kubernetes in production GPU settings\n\n - Proven experience with InfiniBand configuration and troubleshooting\n\n - Strong understanding of NVIDIA GPU architecture, CUDA ecosystem, and driver stack\n\n - Experience with infrastructure automation tools (Ansible, Terraform)\n\n - Proficiency in Python, Bash, and systems programming\n\n - Track record of customer-facing technical leadership\n\nInfrastructure Skills\n\n - NVIDIA driver installation and troubleshooting (CUDA, Fabric Manager, DCGM)\n\n - Container runtime configuration for GPUs (Docker, Containerd, Enroot)\n\n - Linux kernel tuning and performance optimization\n\n - Network topology design for AI workloads\n\n - Power and cooling requirements for high-density GPU deployments\n\nNice to Have\n\n - Experience with 1000+ GPU deployments\n\n - NVIDIA DGX, HGX, or SuperPOD certification\n\n - Distributed training frameworks (PyTorch FSDP, DeepSpeed, Megatron-LM)\n\n - ML framework optimization and profiling\n\n - Experience with AMD MI300 or Intel Gaudi accelerators\n\n - Contributions to open-source HPC/AI infrastructure projects\n\nGrowth Opportunity\n\nYou'll work directly with customers pushing the boundaries of AI, from startups training foundation models to enterprises deploying massive inference infrastructure. You'll collaborate with our world-class engineering team while having direct impact on systems powering the next generation of AI breakthroughs.\n\nWe value expertise and customer obsession - if you're passionate about building reliable, high-performance GPU infrastructure and have a track record of successful large-scale deployments, we want to talk to you.\n\nApply now and join us in our mission to democratize access to planetary scale computing.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "abfa70f7-a6f1-44d2-a6c1-560e1c8477d4", "title": "Member of Technical Staff - Inference", "department": "Engineering", "team": "Engineering", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [{"location": "Remote", "address": {"postalAddress": {"addressCountry": "United States"}}}], "publishedAt": "2025-09-16T23:24:05.274+00:00", "isListed": true, "isRemote": false, "address": {"postalAddress": {"addressRegion": "California", "addressCountry": "United States", "addressLocality": "San Francisco"}}, "jobUrl": "https://jobs.ashbyhq.com/PrimeIntellect/abfa70f7-a6f1-44d2-a6c1-560e1c8477d4", "applyUrl": "https://jobs.ashbyhq.com/PrimeIntellect/abfa70f7-a6f1-44d2-a6c1-560e1c8477d4/application", "descriptionHtml": "<h2><strong>Building the Future of Open Source + Decentralized AI</strong></h2><p style=\"min-height:1.5em\">Prime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.</p><p style=\"min-height:1.5em\">We recently raised $15mm in funding (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.</p><p style=\"min-height:1.5em\"></p><h2><strong>Role Impact</strong></h2><p style=\"min-height:1.5em\">This is a hybrid position spanning cloud LLM serving, LLM inference optimization and RL systems. You will be working on advancing our ability to evaluate and serve models trained with our Environment Hub at scale. The two key areas are:</p><ol style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Building the infrastructure to serve LLMs efficiently at scale.</p></li><li><p style=\"min-height:1.5em\">Optimization and integration of inference systems into our RL training stack.</p></li></ol><p style=\"min-height:1.5em\"></p><h2><strong>Core Technical Responsibilities</strong></h2><p style=\"min-height:1.5em\"><strong>LLM Serving</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\"><strong>Multi\u2011tenant LLM Serving:</strong> Build a multi-tenant LLM serving platform that operates across our cloud GPU fleets.</p></li><li><p style=\"min-height:1.5em\"><strong>GPU\u2011Aware Scheduling:</strong> Design placement and scheduling algorithms for heterogeneous accelerators.</p></li><li><p style=\"min-height:1.5em\"><strong>Resilience &amp; Failover:</strong> Implement multi\u2011region/zone failover and traffic shifting for resilience and cost control.</p></li><li><p style=\"min-height:1.5em\"><strong>Autoscaling &amp; Routing:</strong> Build autoscaling, routing, and load balancing to meet throughput/latency SLOs.</p></li><li><p style=\"min-height:1.5em\"><strong>Model Distribution:</strong> Optimize model distribution and cold-start times across clusters.</p></li></ul><p style=\"min-height:1.5em\"><strong>Inference Optimization &amp; Performance</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\"><strong>Framework Development:</strong> Integrate and contribute to LLM inference frameworks such as vLLM, SGLang, TensorRT\u2011LLM.</p></li><li><p style=\"min-height:1.5em\"><strong>Parallelism and Configuration Tuning:</strong> Optimize configurations for tensor/pipeline/expert parallelism, prefix caching, memory management and other axes for maximum performance.</p></li><li><p style=\"min-height:1.5em\"><strong>End\u2011to\u2011End Performance:</strong> Profile kernels, memory bandwidth and transport; apply techniques such as quantization and speculative decoding.</p></li><li><p style=\"min-height:1.5em\"><strong>Perf Suites:</strong> Develop reproducible performance suites (latency, throughput, context length, batch size, precision).</p></li><li><p style=\"min-height:1.5em\"><strong>RL Integration:</strong> Embed and optimize distributed inference within our RL stack.</p></li></ul><p style=\"min-height:1.5em\"><strong>Platform &amp; Tooling</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\"><strong>CI/CD:</strong> Establish CI/CD with artifact promotion, performance gates, and reproducible builds.</p></li><li><p style=\"min-height:1.5em\"><strong>Observability:</strong> Build metrics, logs, tracing; structured incident response and SLO management.</p></li><li><p style=\"min-height:1.5em\"><strong>Docs &amp; Collaboration:</strong> Document architectures, playbooks, and API contracts; mentor and collaborate cross\u2011functionally.</p></li></ul><h2>Technical Requirements</h2><p style=\"min-height:1.5em\"><strong>Required Experience</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\"><strong>Building ML Systems at Scale:</strong> 3+ years building and running large\u2011scale ML/LLM services with clear latency/availability SLOs.</p></li><li><p style=\"min-height:1.5em\"><strong>Inference Backends:</strong> Hands\u2011on with at least one of vLLM, SGLang, TensorRT\u2011LLM.</p></li><li><p style=\"min-height:1.5em\"><strong>Distributed Serving Infra:</strong> Familiarity with distributed and disaggregated serving infrastructure such as NVIDIA Dynamo.</p></li><li><p style=\"min-height:1.5em\"><strong>Inference Internals:</strong> Deep understanding of prefill vs. decode, KV\u2011cache behavior, batching, sampling, speculative decoding, parallelism strategies.</p></li><li><p style=\"min-height:1.5em\"><strong>Full\u2011Stack Debugging:</strong> Comfortable debugging CUDA/NCCL, drivers/kernels, containers, service mesh/networking, and storage, owning incidents end\u2011to\u2011end.</p></li></ul><p style=\"min-height:1.5em\"><strong>Infrastructure Skills</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\"><strong>Python:</strong> Systems tooling and backend services.</p></li><li><p style=\"min-height:1.5em\"><strong>PyTorch:</strong> LLM Inference engine development and integration, deployment readiness.</p></li><li><p style=\"min-height:1.5em\"><strong>Cloud &amp; Automation:</strong> AWS/GCP service experience, cloud deployment patterns.</p></li><li><p style=\"min-height:1.5em\"><strong>Kubernetes:</strong> Running infrastructure at scale with containers on Kubernetes.</p></li><li><p style=\"min-height:1.5em\"><strong>GPU &amp; Networking:</strong> Architecture, CUDA runtime, NCCL, InfiniBand; GPU\u2011aware bin\u2011packing and scheduling across heterogeneous fleets.</p></li></ul><p style=\"min-height:1.5em\"><strong>Nice to Have</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\"><strong>Kernel\u2011Level Optimization:</strong> Familiarity with CUDA/Triton kernel development; Nsight Systems/Compute profiling.</p></li><li><p style=\"min-height:1.5em\"><strong>Systems Performance Languages:</strong> Rust, C++<strong>.</strong></p></li><li><p style=\"min-height:1.5em\"><strong>Data &amp; Observability:</strong> Kafka/PubSub, Redis, gRPC/Protobuf; Prometheus/Grafana, OpenTelemetry; reliability patterns.</p></li><li><p style=\"min-height:1.5em\"><strong>Infra &amp; Config Automation</strong>: Terraform/Ansible, infrastructure-as-code, reproducible environments</p></li><li><p style=\"min-height:1.5em\"><strong>Open Source:</strong> Contributions to serving, inference, or RL infrastructure projects.</p></li></ul><h2><strong>What We Offer</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\"><strong>Competitive compensation</strong> with significant equity incentives</p></li><li><p style=\"min-height:1.5em\"><strong>Flexible work</strong> arrangement (remote or San Francisco office)</p></li><li><p style=\"min-height:1.5em\"><strong>Full visa sponsorship</strong> and relocation support</p></li><li><p style=\"min-height:1.5em\"><strong>Professional development</strong> budget</p></li><li><p style=\"min-height:1.5em\"><strong>Regular team off-sites</strong> and conference attendance</p></li><li><p style=\"min-height:1.5em\"><strong>Opportunity to shape decentralized AI and RL</strong> at Prime Intellect</p></li></ul><h2><strong>Growth Opportunity</strong></h2><p style=\"min-height:1.5em\">You'll join a team of experienced engineers and researchers working on cutting-edge problems in AI infrastructure. We believe in open development and encourage team members to contribute to the broader AI community through research and open-source contributions.</p><p style=\"min-height:1.5em\">We value potential over perfection. If you're passionate about democratizing AI development, we want to talk to you.</p><p style=\"min-height:1.5em\"><strong>Ready to help shape the future of AI?</strong> Apply now and join us in our mission to make powerful AI models accessible to everyone.</p>", "descriptionPlain": "BUILDING THE FUTURE OF OPEN SOURCE + DECENTRALIZED AI\n\nPrime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.\n\nWe recently raised $15mm in funding (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.\n\n\nROLE IMPACT\n\nThis is a hybrid position spanning cloud LLM serving, LLM inference optimization and RL systems. You will be working on advancing our ability to evaluate and serve models trained with our Environment Hub at scale. The two key areas are:\n\n 1. Building the infrastructure to serve LLMs efficiently at scale.\n\n 2. Optimization and integration of inference systems into our RL training stack.\n\n\nCORE TECHNICAL RESPONSIBILITIES\n\nLLM Serving\n\n - Multi\u2011tenant LLM Serving: Build a multi-tenant LLM serving platform that operates across our cloud GPU fleets.\n\n - GPU\u2011Aware Scheduling: Design placement and scheduling algorithms for heterogeneous accelerators.\n\n - Resilience & Failover: Implement multi\u2011region/zone failover and traffic shifting for resilience and cost control.\n\n - Autoscaling & Routing: Build autoscaling, routing, and load balancing to meet throughput/latency SLOs.\n\n - Model Distribution: Optimize model distribution and cold-start times across clusters.\n\nInference Optimization & Performance\n\n - Framework Development: Integrate and contribute to LLM inference frameworks such as vLLM, SGLang, TensorRT\u2011LLM.\n\n - Parallelism and Configuration Tuning: Optimize configurations for tensor/pipeline/expert parallelism, prefix caching, memory management and other axes for maximum performance.\n\n - End\u2011to\u2011End Performance: Profile kernels, memory bandwidth and transport; apply techniques such as quantization and speculative decoding.\n\n - Perf Suites: Develop reproducible performance suites (latency, throughput, context length, batch size, precision).\n\n - RL Integration: Embed and optimize distributed inference within our RL stack.\n\nPlatform & Tooling\n\n - CI/CD: Establish CI/CD with artifact promotion, performance gates, and reproducible builds.\n\n - Observability: Build metrics, logs, tracing; structured incident response and SLO management.\n\n - Docs & Collaboration: Document architectures, playbooks, and API contracts; mentor and collaborate cross\u2011functionally.\n\n\nTECHNICAL REQUIREMENTS\n\nRequired Experience\n\n - Building ML Systems at Scale: 3+ years building and running large\u2011scale ML/LLM services with clear latency/availability SLOs.\n\n - Inference Backends: Hands\u2011on with at least one of vLLM, SGLang, TensorRT\u2011LLM.\n\n - Distributed Serving Infra: Familiarity with distributed and disaggregated serving infrastructure such as NVIDIA Dynamo.\n\n - Inference Internals: Deep understanding of prefill vs. decode, KV\u2011cache behavior, batching, sampling, speculative decoding, parallelism strategies.\n\n - Full\u2011Stack Debugging: Comfortable debugging CUDA/NCCL, drivers/kernels, containers, service mesh/networking, and storage, owning incidents end\u2011to\u2011end.\n\nInfrastructure Skills\n\n - Python: Systems tooling and backend services.\n\n - PyTorch: LLM Inference engine development and integration, deployment readiness.\n\n - Cloud & Automation: AWS/GCP service experience, cloud deployment patterns.\n\n - Kubernetes: Running infrastructure at scale with containers on Kubernetes.\n\n - GPU & Networking: Architecture, CUDA runtime, NCCL, InfiniBand; GPU\u2011aware bin\u2011packing and scheduling across heterogeneous fleets.\n\nNice to Have\n\n - Kernel\u2011Level Optimization: Familiarity with CUDA/Triton kernel development; Nsight Systems/Compute profiling.\n\n - Systems Performance Languages: Rust, C++.\n\n - Data & Observability: Kafka/PubSub, Redis, gRPC/Protobuf; Prometheus/Grafana, OpenTelemetry; reliability patterns.\n\n - Infra & Config Automation: Terraform/Ansible, infrastructure-as-code, reproducible environments\n\n - Open Source: Contributions to serving, inference, or RL infrastructure projects.\n\n\nWHAT WE OFFER\n\n - Competitive compensation with significant equity incentives\n\n - Flexible work arrangement (remote or San Francisco office)\n\n - Full visa sponsorship and relocation support\n\n - Professional development budget\n\n - Regular team off-sites and conference attendance\n\n - Opportunity to shape decentralized AI and RL at Prime Intellect\n\n\nGROWTH OPPORTUNITY\n\nYou'll join a team of experienced engineers and researchers working on cutting-edge problems in AI infrastructure. We believe in open development and encourage team members to contribute to the broader AI community through research and open-source contributions.\n\nWe value potential over perfection. If you're passionate about democratizing AI development, we want to talk to you.\n\nReady to help shape the future of AI? Apply now and join us in our mission to make powerful AI models accessible to everyone.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "486b3511-7128-46f9-93a5-fc1d748d8852", "title": "Internship", "department": "Others", "team": "Others", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [], "publishedAt": "2025-04-30T01:53:15.223+00:00", "isListed": true, "isRemote": false, "address": {"postalAddress": {"addressRegion": "California", "addressCountry": "United States", "addressLocality": "San Francisco"}}, "jobUrl": "https://jobs.ashbyhq.com/PrimeIntellect/486b3511-7128-46f9-93a5-fc1d748d8852", "applyUrl": "https://jobs.ashbyhq.com/PrimeIntellect/486b3511-7128-46f9-93a5-fc1d748d8852/application", "descriptionHtml": "<p style=\"min-height:1.5em\">Prime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.</p><p style=\"min-height:1.5em\">We\u2019re looking for exceptional interns who\u2019ve already built real systems, contributed to open-source, or gone deep across technical domains.</p><p style=\"min-height:1.5em\">If you thrive in open-ended, high-stakes problem spaces and want to push the limits of open, distributed AI, we want to hear from you. Whether your strength is in AI, systems, distributed compute, cryptography, or something unexpected, what matters is how fast you learn, how well you execute, and how deeply you think.</p><p style=\"min-height:1.5em\">We recently raised $15M (total $20M) from Founders Fund, Menlo Ventures, and angels including Andrej Karpathy, Tri Dao, Dylan Patel, Clem Delangue, and Emad Mostaque.</p><p style=\"min-height:1.5em\">Tell us what excites you about PrimeIntellect, something impressive you\u2019ve built, and how you\u2019d accelerate decentralized AGI.</p>", "descriptionPlain": "Prime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.\n\nWe\u2019re looking for exceptional interns who\u2019ve already built real systems, contributed to open-source, or gone deep across technical domains.\n\nIf you thrive in open-ended, high-stakes problem spaces and want to push the limits of open, distributed AI, we want to hear from you. Whether your strength is in AI, systems, distributed compute, cryptography, or something unexpected, what matters is how fast you learn, how well you execute, and how deeply you think.\n\nWe recently raised $15M (total $20M) from Founders Fund, Menlo Ventures, and angels including Andrej Karpathy, Tri Dao, Dylan Patel, Clem Delangue, and Emad Mostaque.\n\nTell us what excites you about PrimeIntellect, something impressive you\u2019ve built, and how you\u2019d accelerate decentralized AGI.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "b9343f5d-326d-4b01-b6a7-acf56cffe3ac", "title": "Open Application for Unconventional Talent", "department": "Others", "team": "Others", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [{"location": "Remote", "address": {"postalAddress": {"addressCountry": "United States"}}}], "publishedAt": "2025-02-17T15:49:27.320+00:00", "isListed": true, "isRemote": false, "address": {"postalAddress": {"addressRegion": "California", "addressCountry": "United States", "addressLocality": "San Francisco"}}, "jobUrl": "https://jobs.ashbyhq.com/PrimeIntellect/b9343f5d-326d-4b01-b6a7-acf56cffe3ac", "applyUrl": "https://jobs.ashbyhq.com/PrimeIntellect/b9343f5d-326d-4b01-b6a7-acf56cffe3ac/application", "descriptionHtml": "<p style=\"min-height:1.5em\">Prime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.</p><p style=\"min-height:1.5em\">If you\u2019ve built complex technical systems, contributed meaningfully to open-source projects, or mastered multiple domains, we want to hear from you. Whether your expertise is in AI, distributed computing, cryptography, systems programming, or something unexpected, what matters is your ability to learn fast, think rigorously, and execute.</p><p style=\"min-height:1.5em\">We recently raised <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.primeintellect.ai/blog/fundraise\">$15mm in funding</a> (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.</p><p style=\"min-height:1.5em\">Tell us what excites you about PrimeIntellect, something impressive that that you\u2019ve built, and how you\u2019d accelerate open and decentralized AGI.</p>", "descriptionPlain": "Prime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.\n\nIf you\u2019ve built complex technical systems, contributed meaningfully to open-source projects, or mastered multiple domains, we want to hear from you. Whether your expertise is in AI, distributed computing, cryptography, systems programming, or something unexpected, what matters is your ability to learn fast, think rigorously, and execute.\n\nWe recently raised $15mm in funding https://www.primeintellect.ai/blog/fundraise (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.\n\nTell us what excites you about PrimeIntellect, something impressive that that you\u2019ve built, and how you\u2019d accelerate open and decentralized AGI.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "8bd52610-175c-42a7-a7cd-b29c45f9d305", "title": "Research Engineer - Distributed Training", "department": "Research", "team": "Research", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [{"location": "Remote", "address": {"postalAddress": {"addressCountry": "United States"}}}], "publishedAt": "2024-08-21T17:53:12.688+00:00", "isListed": true, "isRemote": false, "address": {"postalAddress": {"addressRegion": "California", "addressCountry": "United States", "addressLocality": "San Francisco"}}, "jobUrl": "https://jobs.ashbyhq.com/PrimeIntellect/8bd52610-175c-42a7-a7cd-b29c45f9d305", "applyUrl": "https://jobs.ashbyhq.com/PrimeIntellect/8bd52610-175c-42a7-a7cd-b29c45f9d305/application", "descriptionHtml": "<p style=\"min-height:1.5em\">Prime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.</p><p style=\"min-height:1.5em\">As a Research Engineer working on Distributed Training, you'll play a crucial role in shaping our technological direction, focusing on our decentralizing AI training stack. If you love scaling things and maximizing training efficiency, this role is for you.</p><p style=\"min-height:1.5em\"></p><h2><strong><u>Responsibilities</u></strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Lead and participate in novel research to build a massive scale, highly reliable and secure decentralized training orchestration solution</p></li><li><p style=\"min-height:1.5em\">Optimize the performance, cost, and resource utilization of AI workloads by leveraging the most recent advances for compute &amp; memory optimization techniques.</p></li><li><p style=\"min-height:1.5em\">Contribute to the development of our open-source libraries and frameworks for distributed model training.</p></li><li><p style=\"min-height:1.5em\">Publish research in top-tier AI conferences such as ICML &amp; NeurIPS.</p></li><li><p style=\"min-height:1.5em\">Distill highly technical project outcomes in layman approachable technical blogs to our customers and developers.</p></li><li><p style=\"min-height:1.5em\">Stay up-to-date with the latest advancements in AI/ML infrastructure and tools, decentralized training research and proactively identify opportunities to enhance our platform's capabilities and user experience.</p></li></ul><h2><strong><u>Requirements</u></strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Strong background in AI/ML engineering, with extensive experience in designing and implementing end-to-end pipelines for training and deploying large-scale AI models.</p></li><li><p style=\"min-height:1.5em\">Deep expertise in distributed training techniques, frameworks (e.g., PyTorch Distributed, DeepSpeed, MosaicML\u2019s LLM Foundry), and tools (e.g. Ray) for optimizing the performance and scalability of AI workloads.</p></li><li><p style=\"min-height:1.5em\">Experience in large-scale model training incl. distributed training techniques such as data, tensor &amp; pipeline parallelism</p></li><li><p style=\"min-height:1.5em\">Solid understanding of MLOps best practices, including model versioning, experiment tracking, and continuous integration/deployment (CI/CD) pipelines.</p></li><li><p style=\"min-height:1.5em\">Passion for advancing the state-of-the-art in decentralized AI model training and democratizing access to AI capabilities for researchers, developers, and businesses worldwide.</p></li><li><p style=\"min-height:1.5em\">If you're not familiar with these, but feel like that you can contribute to our mission and you're a high-energy person, get familiar with these resources (<a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://a.co/d/frW8MHY\">here</a>, <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://a.co/d/4WRhR0Y\">here</a> and <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://github.com/stas00/ml-engineering/tree/master\">here</a>) and please reach out!</p></li></ul><h2></h2><h2><strong><u>Benefits &amp; Perks</u></strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Competitive compensation, including equity incentives, aligning your success with the growth and impact of Prime Intellect.</p></li><li><p style=\"min-height:1.5em\">Flexible work arrangements, with the option to work remotely or in-person at our offices in San Francisco.</p></li><li><p style=\"min-height:1.5em\">Visa sponsorship and relocation assistance for international candidates.</p></li><li><p style=\"min-height:1.5em\">Quarterly team off-sites, hackathons, conferences and learning opportunities.</p></li><li><p style=\"min-height:1.5em\">Opportunity to work with a talented, hard-working and mission-driven team, united by a shared passion for leveraging technology to accelerate science and AI.</p></li></ul><p style=\"min-height:1.5em\">We recently raised <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.primeintellect.ai/blog/fundraise\">$15mm in funding</a> (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.</p><p style=\"min-height:1.5em\">If you're excited about the opportunity to build the foundation for the future of decentralized AI and create a platform that empowers developers and researchers to push the boundaries of what's possible, we'd love to hear from you.</p>", "descriptionPlain": "Prime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.\n\nAs a Research Engineer working on Distributed Training, you'll play a crucial role in shaping our technological direction, focusing on our decentralizing AI training stack. If you love scaling things and maximizing training efficiency, this role is for you.\n\n\nRESPONSIBILITIES\n\n - Lead and participate in novel research to build a massive scale, highly reliable and secure decentralized training orchestration solution\n\n - Optimize the performance, cost, and resource utilization of AI workloads by leveraging the most recent advances for compute & memory optimization techniques.\n\n - Contribute to the development of our open-source libraries and frameworks for distributed model training.\n\n - Publish research in top-tier AI conferences such as ICML & NeurIPS.\n\n - Distill highly technical project outcomes in layman approachable technical blogs to our customers and developers.\n\n - Stay up-to-date with the latest advancements in AI/ML infrastructure and tools, decentralized training research and proactively identify opportunities to enhance our platform's capabilities and user experience.\n\n\nREQUIREMENTS\n\n - Strong background in AI/ML engineering, with extensive experience in designing and implementing end-to-end pipelines for training and deploying large-scale AI models.\n\n - Deep expertise in distributed training techniques, frameworks (e.g., PyTorch Distributed, DeepSpeed, MosaicML\u2019s LLM Foundry), and tools (e.g. Ray) for optimizing the performance and scalability of AI workloads.\n\n - Experience in large-scale model training incl. distributed training techniques such as data, tensor & pipeline parallelism\n\n - Solid understanding of MLOps best practices, including model versioning, experiment tracking, and continuous integration/deployment (CI/CD) pipelines.\n\n - Passion for advancing the state-of-the-art in decentralized AI model training and democratizing access to AI capabilities for researchers, developers, and businesses worldwide.\n\n - If you're not familiar with these, but feel like that you can contribute to our mission and you're a high-energy person, get familiar with these resources (here https://a.co/d/frW8MHY, here https://a.co/d/4WRhR0Y and here https://github.com/stas00/ml-engineering/tree/master) and please reach out!\n\n\n\n\n\nBENEFITS & PERKS\n\n - Competitive compensation, including equity incentives, aligning your success with the growth and impact of Prime Intellect.\n\n - Flexible work arrangements, with the option to work remotely or in-person at our offices in San Francisco.\n\n - Visa sponsorship and relocation assistance for international candidates.\n\n - Quarterly team off-sites, hackathons, conferences and learning opportunities.\n\n - Opportunity to work with a talented, hard-working and mission-driven team, united by a shared passion for leveraging technology to accelerate science and AI.\n\nWe recently raised $15mm in funding https://www.primeintellect.ai/blog/fundraise (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.\n\nIf you're excited about the opportunity to build the foundation for the future of decentralized AI and create a platform that empowers developers and researchers to push the boundaries of what's possible, we'd love to hear from you.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "46d9d060-5f48-4491-848f-bafbeb3a4325", "title": "Applied Research - RL & Agents", "department": "Research", "team": "Research", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [{"location": "Remote", "address": {"postalAddress": {"addressCountry": "United States"}}}], "publishedAt": "2025-09-26T06:39:24.777+00:00", "isListed": true, "isRemote": false, "address": {"postalAddress": {"addressRegion": "California", "addressCountry": "United States", "addressLocality": "San Francisco"}}, "jobUrl": "https://jobs.ashbyhq.com/PrimeIntellect/46d9d060-5f48-4491-848f-bafbeb3a4325", "applyUrl": "https://jobs.ashbyhq.com/PrimeIntellect/46d9d060-5f48-4491-848f-bafbeb3a4325/application", "descriptionHtml": "<p style=\"min-height:1.5em\"><strong>Building the Open Superintelligence Lab</strong><br />Prime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.</p><p style=\"min-height:1.5em\">We recently raised <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.primeintellect.ai/blog/fundraise\">$15mm in funding</a> (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.</p><h2><br />Role Impact</h2><p style=\"min-height:1.5em\">This is a customer facing role at the intersection of cutting-edge RL/post-training methods and applied agent systems. You\u2019ll have a direct impact on shaping how advanced models are aligned, deployed, and used in the real world by:</p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\"><strong>Advancing Agent Capabilities</strong>: Designing and iterating on next-generation AI agents that tackle real workloads\u2014workflow automation, reasoning-intensive tasks, and decision-making at scale.</p></li><li><p style=\"min-height:1.5em\"><strong>Building Robust Infrastructure</strong>: Developing the distributed systems and coordination frameworks that enable these agents to operate reliably, efficiently, and at massive scale.</p></li><li><p style=\"min-height:1.5em\"><strong>Bridge Between Customers &amp; Research</strong>: Translate customer needs into clear technical requirements that guide product and research priorities.</p></li><li><p style=\"min-height:1.5em\"><strong>Prototype in the Field</strong>: Rapidly design and deploy agents, evals, and harnesses alongside customers to validate solutions.<br /></p></li></ul><p style=\"min-height:1.5em\"><strong>Customer-Facing Engineering</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Work side-by-side with customers to deeply understand workflows and bottlenecks.</p></li><li><p style=\"min-height:1.5em\">Prototype agents and eval harnesses tailored to real use cases, then hand off hardened systems to core teams.</p></li><li><p style=\"min-height:1.5em\">Translate customer insights into roadmap and research direction.</p></li></ul><p style=\"min-height:1.5em\"><strong>Post-training &amp; Reinforcement Learning</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Design and implement novel RL and post-training methods (RLHF, RLVR, GRPO, etc.) to align large models with domain-specific tasks.</p></li><li><p style=\"min-height:1.5em\">Build evaluation harnesses and verifiers to measure reasoning, robustness, and agentic behavior in real-world workflows.</p></li><li><p style=\"min-height:1.5em\">Prototype multi-agent and memory-augmented systems to expand capabilities for customer-facing solutions.</p></li></ul><p style=\"min-height:1.5em\"><strong>Agent Development &amp; Infrastructure</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Rapidly prototype and iterate on AI agents for automation, workflow orchestration, and decision-making.</p></li><li><p style=\"min-height:1.5em\">Extend and integrate with agent frameworks to support evolving feature requests and performance requirements.</p></li><li><p style=\"min-height:1.5em\">Architect and maintain distributed training/inference pipelines, ensuring scalability and cost efficiency.</p></li><li><p style=\"min-height:1.5em\">Develop observability and monitoring (Prometheus, Grafana, tracing) to ensure reliability and performance in production deployments..</p></li></ul><p style=\"min-height:1.5em\"></p><h2>Requirements</h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Strong background in machine learning engineering, with experience in post-training, RL, or large-scale model alignment.</p></li><li><p style=\"min-height:1.5em\">Deep expertise in distributed training/inference frameworks (e.g., vLLM, sglang, Ray, Accelerate).</p></li><li><p style=\"min-height:1.5em\">Experience deploying containerized systems at scale (Docker, Kubernetes, Terraform).</p></li><li><p style=\"min-height:1.5em\">Track record of research contributions (publications, open-source contributions, benchmarks) in ML/RL.</p></li><li><p style=\"min-height:1.5em\">Passion for advancing the state-of-the-art in reasoning and building practical, agentic AI systems.</p></li></ul><p style=\"min-height:1.5em\"></p><h2>What We Offer</h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\"><strong>Competitive Compensation</strong> + equity incentives</p></li><li><p style=\"min-height:1.5em\"><strong>Flexible Work</strong> (remote or San Francisco)</p></li><li><p style=\"min-height:1.5em\"><strong>Visa Sponsorship</strong> &amp; relocation support</p></li><li><p style=\"min-height:1.5em\"><strong>Professional Development</strong> budget</p></li><li><p style=\"min-height:1.5em\"><strong>Team Off-sites</strong> &amp; conference attendance</p></li></ul><h2><br />Growth Opportunity</h2><p style=\"min-height:1.5em\">You\u2019ll join a mission-driven team working at the frontier of open, superintelligence infra. In this role, you\u2019ll have the opportunity to:</p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Shape the evolution of agent-driven solutions\u2014from research breakthroughs to production systems used by real customers.</p></li><li><p style=\"min-height:1.5em\">Collaborate with leading researchers, engineers, and partners pushing the boundaries of RL and post-training.</p></li><li><p style=\"min-height:1.5em\">Grow with a fast-moving organization where your contributions directly influence both the technical direction and the broader AI ecosystem.</p></li></ul><p style=\"min-height:1.5em\">If you\u2019re excited to move fast, build boldly, and help define how agentic AI is developed and deployed, we\u2019d love to hear from you.</p><p style=\"min-height:1.5em\"></p><p style=\"min-height:1.5em\"><strong>Ready to build the open superintelligence infrastructure of tomorrow?</strong><br />Apply now to help us make powerful, open AGI accessible to everyone.</p>", "descriptionPlain": "Building the Open Superintelligence Lab\nPrime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.\n\nWe recently raised $15mm in funding https://www.primeintellect.ai/blog/fundraise (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.\n\n\n\nROLE IMPACT\n\nThis is a customer facing role at the intersection of cutting-edge RL/post-training methods and applied agent systems. You\u2019ll have a direct impact on shaping how advanced models are aligned, deployed, and used in the real world by:\n\n - Advancing Agent Capabilities: Designing and iterating on next-generation AI agents that tackle real workloads\u2014workflow automation, reasoning-intensive tasks, and decision-making at scale.\n\n - Building Robust Infrastructure: Developing the distributed systems and coordination frameworks that enable these agents to operate reliably, efficiently, and at massive scale.\n\n - Bridge Between Customers & Research: Translate customer needs into clear technical requirements that guide product and research priorities.\n\n - Prototype in the Field: Rapidly design and deploy agents, evals, and harnesses alongside customers to validate solutions.\n   \n\nCustomer-Facing Engineering\n\n - Work side-by-side with customers to deeply understand workflows and bottlenecks.\n\n - Prototype agents and eval harnesses tailored to real use cases, then hand off hardened systems to core teams.\n\n - Translate customer insights into roadmap and research direction.\n\nPost-training & Reinforcement Learning\n\n - Design and implement novel RL and post-training methods (RLHF, RLVR, GRPO, etc.) to align large models with domain-specific tasks.\n\n - Build evaluation harnesses and verifiers to measure reasoning, robustness, and agentic behavior in real-world workflows.\n\n - Prototype multi-agent and memory-augmented systems to expand capabilities for customer-facing solutions.\n\nAgent Development & Infrastructure\n\n - Rapidly prototype and iterate on AI agents for automation, workflow orchestration, and decision-making.\n\n - Extend and integrate with agent frameworks to support evolving feature requests and performance requirements.\n\n - Architect and maintain distributed training/inference pipelines, ensuring scalability and cost efficiency.\n\n - Develop observability and monitoring (Prometheus, Grafana, tracing) to ensure reliability and performance in production deployments..\n\n\nREQUIREMENTS\n\n - Strong background in machine learning engineering, with experience in post-training, RL, or large-scale model alignment.\n\n - Deep expertise in distributed training/inference frameworks (e.g., vLLM, sglang, Ray, Accelerate).\n\n - Experience deploying containerized systems at scale (Docker, Kubernetes, Terraform).\n\n - Track record of research contributions (publications, open-source contributions, benchmarks) in ML/RL.\n\n - Passion for advancing the state-of-the-art in reasoning and building practical, agentic AI systems.\n\n\nWHAT WE OFFER\n\n - Competitive Compensation + equity incentives\n\n - Flexible Work (remote or San Francisco)\n\n - Visa Sponsorship & relocation support\n\n - Professional Development budget\n\n - Team Off-sites & conference attendance\n\n\n\nGROWTH OPPORTUNITY\n\nYou\u2019ll join a mission-driven team working at the frontier of open, superintelligence infra. In this role, you\u2019ll have the opportunity to:\n\n - Shape the evolution of agent-driven solutions\u2014from research breakthroughs to production systems used by real customers.\n\n - Collaborate with leading researchers, engineers, and partners pushing the boundaries of RL and post-training.\n\n - Grow with a fast-moving organization where your contributions directly influence both the technical direction and the broader AI ecosystem.\n\nIf you\u2019re excited to move fast, build boldly, and help define how agentic AI is developed and deployed, we\u2019d love to hear from you.\n\nReady to build the open superintelligence infrastructure of tomorrow?\nApply now to help us make powerful, open AGI accessible to everyone.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "8d1d79bf-0032-4e37-a7dd-ce53ebc5a612", "title": "Founding GTM Lead", "department": "Operations", "team": "Operations", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [], "publishedAt": "2025-10-13T16:50:29.734+00:00", "isListed": true, "isRemote": false, "address": {"postalAddress": {"addressRegion": "California", "addressCountry": "United States", "addressLocality": "San Francisco"}}, "jobUrl": "https://jobs.ashbyhq.com/PrimeIntellect/8d1d79bf-0032-4e37-a7dd-ce53ebc5a612", "applyUrl": "https://jobs.ashbyhq.com/PrimeIntellect/8d1d79bf-0032-4e37-a7dd-ce53ebc5a612/application", "descriptionHtml": "<p style=\"min-height:1.5em\">Prime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.</p><p style=\"min-height:1.5em\">We aggregate global GPU and XPU resources, enabling researchers and developers to collaboratively train state-of-the-art models using distributed training. As a founding member of our <strong>Go-To-Market (GTM) team</strong>, you\u2019ll be at the forefront of shaping our sales and marketing strategies to secure partnerships, expand our GPU marketplace, and grow a long-term client base.</p><p style=\"min-height:1.5em\"></p><h2><strong><u>Your Role</u></strong></h2><p style=\"min-height:1.5em\">As a key leader, you\u2019ll drive revenue growth and foster partnerships that position Prime Intellect as a trusted compute partner for companies scaling their resources or developing next-gen LLMs and multimodal models. You'll architect and execute Prime Intellect's comprehensive revenue strategy, focusing on building our sales infrastructure while driving revenue through enterprise and mid-market compute partnerships. You'll be responsible for establishing our sales architecture, developing multi-channel sales motions, and implementing revenue operations systems that enable data-driven growth.</p><p style=\"min-height:1.5em\"></p><h2><strong><u>Responsibilities</u></strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Identify and nurture high-value leads through targeted prospecting and inbound/outbound strategies.</p></li><li><p style=\"min-height:1.5em\">Develop and execute GTM strategies to launch and scale our decentralized training platform in key U.S. and European markets.</p></li><li><p style=\"min-height:1.5em\">Build strategic partnerships with industry leaders, including cloud providers and AI tool developers, to expand our ecosystem.</p></li><li><p style=\"min-height:1.5em\">Refine and communicate our unique value proposition to diverse audiences, from technical teams to business leaders.</p></li><li><p style=\"min-height:1.5em\">Lead the creation of compelling sales and marketing materials such as case studies, white papers, and customer success stories.</p></li><li><p style=\"min-height:1.5em\">Collaborate closely with marketing and engineering teams to align product features with market needs and feedback.</p></li><li><p style=\"min-height:1.5em\">Drive comprehensive revenue strategy targeting upper-mid market and enterprise clients ($100k+ ACV), while maintaining efficient velocity for smaller deals ($10k-$100k)</p></li><li><p style=\"min-height:1.5em\">Build and execute Prime Intellect's complete sales playbook, including methodologies, processes, and best practices</p></li><li><p style=\"min-height:1.5em\">Design and launch a hybrid SDR program incorporating in-house teams, third-party partners, and AI agent capabilities</p></li><li><p style=\"min-height:1.5em\">Implement sales technology stack and CRM architecture to enable data-driven decision making</p></li><li><p style=\"min-height:1.5em\">Build sales enablement infrastructure including training programs, content libraries, and analytics systems</p></li><li><p style=\"min-height:1.5em\">Plan and execute strategic events for prospect engagement and customer relationship building</p></li><li><p style=\"min-height:1.5em\">Develop and manage strategic partnerships to expand market reach</p></li><li><p style=\"min-height:1.5em\">Create and optimize deal cycles from prospect to close through data-driven insights</p></li></ul><p style=\"min-height:1.5em\"></p><h2><strong><u>What We\u2019re Looking For</u></strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Proven experience leading GTM strategies for AI/ML products, with a deep understanding of the competitive landscape.</p></li><li><p style=\"min-height:1.5em\">Expertise in translating complex technical concepts into clear, impactful messaging for both technical and non-technical audiences.</p></li><li><p style=\"min-height:1.5em\">A track record of building and nurturing partnerships that drive growth and adoption within the AI/ML ecosystem.</p></li><li><p style=\"min-height:1.5em\">Strong communication and leadership skills, with demonstrated success in aligning teams to execute strategic initiatives.</p></li><li><p style=\"min-height:1.5em\">Familiarity with tools like LinkedIn, HubSpot, and industry-standard AI/ML tools and platforms.</p></li><li><p style=\"min-height:1.5em\">Deep understanding of sales technology stacks and revenue operations</p></li><li><p style=\"min-height:1.5em\">Strong analytical mindset with experience in sales performance optimization and forecasting</p></li><li><p style=\"min-height:1.5em\">Experience in building customer success frameworks and measuring customer value metrics</p></li></ul><p style=\"min-height:1.5em\"></p><h2><strong><u>Benefits &amp; Perks</u></strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Competitive compensation, including equity incentives, aligning your success with the growth and impact of Prime Intellect.</p></li><li><p style=\"min-height:1.5em\">Flexible work arrangements, with the option to work remotely or in-person at our offices in San Francisco.</p></li><li><p style=\"min-height:1.5em\">Visa sponsorship and relocation assistance for international candidates.</p></li><li><p style=\"min-height:1.5em\">Quarterly team off-sites, hackathons, conferences and learning opportunities.</p></li><li><p style=\"min-height:1.5em\">Opportunity to work with a talented, hard-working and mission-driven team, united by a shared passion for leveraging technology to accelerate science and AI.</p></li></ul><p style=\"min-height:1.5em\"></p><p style=\"min-height:1.5em\">We recently raised <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.primeintellect.ai/blog/fundraise\">$15mm in funding</a> (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.</p><p style=\"min-height:1.5em\">If you're excited about the opportunity to build the foundation for the future of decentralized AI and create a platform that empowers developers and researchers to push the boundaries of what's possible, we'd love to hear from you.</p>", "descriptionPlain": "Prime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.\n\nWe aggregate global GPU and XPU resources, enabling researchers and developers to collaboratively train state-of-the-art models using distributed training. As a founding member of our Go-To-Market (GTM) team, you\u2019ll be at the forefront of shaping our sales and marketing strategies to secure partnerships, expand our GPU marketplace, and grow a long-term client base.\n\n\nYOUR ROLE\n\nAs a key leader, you\u2019ll drive revenue growth and foster partnerships that position Prime Intellect as a trusted compute partner for companies scaling their resources or developing next-gen LLMs and multimodal models. You'll architect and execute Prime Intellect's comprehensive revenue strategy, focusing on building our sales infrastructure while driving revenue through enterprise and mid-market compute partnerships. You'll be responsible for establishing our sales architecture, developing multi-channel sales motions, and implementing revenue operations systems that enable data-driven growth.\n\n\nRESPONSIBILITIES\n\n - Identify and nurture high-value leads through targeted prospecting and inbound/outbound strategies.\n\n - Develop and execute GTM strategies to launch and scale our decentralized training platform in key U.S. and European markets.\n\n - Build strategic partnerships with industry leaders, including cloud providers and AI tool developers, to expand our ecosystem.\n\n - Refine and communicate our unique value proposition to diverse audiences, from technical teams to business leaders.\n\n - Lead the creation of compelling sales and marketing materials such as case studies, white papers, and customer success stories.\n\n - Collaborate closely with marketing and engineering teams to align product features with market needs and feedback.\n\n - Drive comprehensive revenue strategy targeting upper-mid market and enterprise clients ($100k+ ACV), while maintaining efficient velocity for smaller deals ($10k-$100k)\n\n - Build and execute Prime Intellect's complete sales playbook, including methodologies, processes, and best practices\n\n - Design and launch a hybrid SDR program incorporating in-house teams, third-party partners, and AI agent capabilities\n\n - Implement sales technology stack and CRM architecture to enable data-driven decision making\n\n - Build sales enablement infrastructure including training programs, content libraries, and analytics systems\n\n - Plan and execute strategic events for prospect engagement and customer relationship building\n\n - Develop and manage strategic partnerships to expand market reach\n\n - Create and optimize deal cycles from prospect to close through data-driven insights\n\n\nWHAT WE\u2019RE LOOKING FOR\n\n - Proven experience leading GTM strategies for AI/ML products, with a deep understanding of the competitive landscape.\n\n - Expertise in translating complex technical concepts into clear, impactful messaging for both technical and non-technical audiences.\n\n - A track record of building and nurturing partnerships that drive growth and adoption within the AI/ML ecosystem.\n\n - Strong communication and leadership skills, with demonstrated success in aligning teams to execute strategic initiatives.\n\n - Familiarity with tools like LinkedIn, HubSpot, and industry-standard AI/ML tools and platforms.\n\n - Deep understanding of sales technology stacks and revenue operations\n\n - Strong analytical mindset with experience in sales performance optimization and forecasting\n\n - Experience in building customer success frameworks and measuring customer value metrics\n\n\nBENEFITS & PERKS\n\n - Competitive compensation, including equity incentives, aligning your success with the growth and impact of Prime Intellect.\n\n - Flexible work arrangements, with the option to work remotely or in-person at our offices in San Francisco.\n\n - Visa sponsorship and relocation assistance for international candidates.\n\n - Quarterly team off-sites, hackathons, conferences and learning opportunities.\n\n - Opportunity to work with a talented, hard-working and mission-driven team, united by a shared passion for leveraging technology to accelerate science and AI.\n\nWe recently raised $15mm in funding https://www.primeintellect.ai/blog/fundraise (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.\n\nIf you're excited about the opportunity to build the foundation for the future of decentralized AI and create a platform that empowers developers and researchers to push the boundaries of what's possible, we'd love to hear from you.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "fd798bc6-b2a5-4d73-ac18-77730e24a6bd", "title": "Lead Product Designer", "department": "Others", "team": "Others", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [{"location": "Remote", "address": {"postalAddress": {"addressCountry": "United States"}}}], "publishedAt": "2025-02-17T16:13:59.635+00:00", "isListed": true, "isRemote": false, "address": {"postalAddress": {"addressRegion": "California", "addressCountry": "United States", "addressLocality": "San Francisco"}}, "jobUrl": "https://jobs.ashbyhq.com/PrimeIntellect/fd798bc6-b2a5-4d73-ac18-77730e24a6bd", "applyUrl": "https://jobs.ashbyhq.com/PrimeIntellect/fd798bc6-b2a5-4d73-ac18-77730e24a6bd/application", "descriptionHtml": "<h3><strong>Creating Open + Decentralized AGI</strong></h3><p style=\"min-height:1.5em\">Prime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.</p><p style=\"min-height:1.5em\">We recently raised <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.primeintellect.ai/blog/fundraise\">$15mm in funding</a> (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.</p><h3><br /><strong>Role Impact</strong></h3><p style=\"min-height:1.5em\">As <strong>Product Designer</strong>, you\u2019ll define the design layer of Prime Intellect\u2019s platform \u2014 shaping how developers, researchers, and engineers interact with decentralized intelligence. You\u2019ll work closely with internal engineers and AI researchers to translate complex systems \u2014 reinforcement learning, compute orchestration, verifiable evals \u2014 into clear, intuitive, and powerful experiences.</p><p style=\"min-height:1.5em\">This is not a marketing or brand design role. It\u2019s about <strong>designing tools and experiences for people who build intelligence itself</strong> \u2014 product experiences that makes advanced AI infrastructure and tools simple, accessible and usable by many developers.<br /><br /><strong>Core Responsibilities</strong></p><p style=\"min-height:1.5em\"><strong>Product &amp; Platform Design</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Design interfaces and workflows across the Prime Intellect platform \u2014 from compute orchestration to RL training and evaluation</p></li><li><p style=\"min-height:1.5em\">Collaborate with engineers and researchers to map complex backend systems into intuitive product surfaces</p></li><li><p style=\"min-height:1.5em\">Own end-to-end product UX: from wireframes and interaction flows to production-ready design</p></li><li><p style=\"min-height:1.5em\">Develop and maintain a consistent design system balancing clarity, performance, and extensibility</p></li></ul><p style=\"min-height:1.5em\"><strong>Developer Experience</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Understand and design for technical audiences: AI researchers, ML engineers, and devops teams</p></li><li><p style=\"min-height:1.5em\">Translate reinforcement learning concepts (training loops, environments, verifiers, evals) into usable visual primitives and workflows</p></li><li><p style=\"min-height:1.5em\">Help shape the \u201cdeveloper ergonomics\u201d of the platform: onboarding, feedback loops, observability, and visual debugging tools</p></li><li><p style=\"min-height:1.5em\">Design for interactions between developer frameworks and platform UI, ensuring the e2e experience is simple, understandable, and fulfills the user's objectives</p></li></ul><h3><br /><strong>What We\u2019re Looking For</strong></h3><p style=\"min-height:1.5em\"><strong>Core Skills &amp; Experience</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Strong portfolio demonstrating end-to-end product design for technical or data-driven tools.</p></li><li><p style=\"min-height:1.5em\">Proficiency in Figma, and fluency in systems design, UX architecture, and visual hierarchy.</p></li><li><p style=\"min-height:1.5em\">Experience designing for developers, researchers, or technical domains \u2014 dashboards, APIs, model tooling, or infra products.</p></li><li><p style=\"min-height:1.5em\">Familiarity with AI/ML concepts (training, evaluation, RL, fine-tuning) and comfort engaging with engineers on these topics.</p></li><li><p style=\"min-height:1.5em\">Fundamental understanding of front-end principles (HTML, CSS, JS a plus)</p></li></ul><p style=\"min-height:1.5em\"><br /><strong>Nice to Have</strong></p><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Prior experience designing ML research tools, IDEs, or developer platforms.</p></li><li><p style=\"min-height:1.5em\">Comfort doing lightweight full-stack development to implement designs</p></li></ul><h3><br /><strong>What We Offer</strong></h3><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Competitive compensation with significant equity incentives</p></li><li><p style=\"min-height:1.5em\">Remote-first with a San Francisco hub</p></li><li><p style=\"min-height:1.5em\">Budget for tools, software, and experimental projects</p></li><li><p style=\"min-height:1.5em\">Opportunities to attend and shape AI/tech conferences</p></li><li><p style=\"min-height:1.5em\">A chance to define the aesthetics of the decentralized AGI era</p></li></ul><p style=\"min-height:1.5em\">If you see design as more than visuals\u2014if you shape experiences, interfaces, and systems with precision and intent\u2014we want to build with you.</p><p style=\"min-height:1.5em\"><strong>Ready to craft the future of AI? Apply now.</strong></p>", "descriptionPlain": "CREATING OPEN + DECENTRALIZED AGI\n\nPrime Intellect is building the open superintelligence stack - from frontier agentic models to the infra that enables anyone to create, train, and deploy them. We aggregate and orchestrate global compute into a single control plane and pair it with the full rl post-training stack: environments, secure sandboxes, verifiable evals, and our async RL trainer. We enable researchers, startups and enterprises to run end-to-end reinforcement learning at frontier scale, adapting models to real tools, workflows, and deployment contexts.\n\nWe recently raised $15mm in funding https://www.primeintellect.ai/blog/fundraise (total of $20mm raised) led by Founders Fund, with participation from Menlo Ventures and prominent angels including Andrej Karpathy (Eureka AI, Tesla, OpenAI), Tri Dao (Chief Scientific Officer of Together AI), Dylan Patel (SemiAnalysis), Clem Delangue (Huggingface), Emad Mostaque (Stability AI) and many others.\n\n\n\nROLE IMPACT\n\nAs Product Designer, you\u2019ll define the design layer of Prime Intellect\u2019s platform \u2014 shaping how developers, researchers, and engineers interact with decentralized intelligence. You\u2019ll work closely with internal engineers and AI researchers to translate complex systems \u2014 reinforcement learning, compute orchestration, verifiable evals \u2014 into clear, intuitive, and powerful experiences.\n\nThis is not a marketing or brand design role. It\u2019s about designing tools and experiences for people who build intelligence itself \u2014 product experiences that makes advanced AI infrastructure and tools simple, accessible and usable by many developers.\n\nCore Responsibilities\n\nProduct & Platform Design\n\n - Design interfaces and workflows across the Prime Intellect platform \u2014 from compute orchestration to RL training and evaluation\n\n - Collaborate with engineers and researchers to map complex backend systems into intuitive product surfaces\n\n - Own end-to-end product UX: from wireframes and interaction flows to production-ready design\n\n - Develop and maintain a consistent design system balancing clarity, performance, and extensibility\n\nDeveloper Experience\n\n - Understand and design for technical audiences: AI researchers, ML engineers, and devops teams\n\n - Translate reinforcement learning concepts (training loops, environments, verifiers, evals) into usable visual primitives and workflows\n\n - Help shape the \u201cdeveloper ergonomics\u201d of the platform: onboarding, feedback loops, observability, and visual debugging tools\n\n - Design for interactions between developer frameworks and platform UI, ensuring the e2e experience is simple, understandable, and fulfills the user's objectives\n\n\n\nWHAT WE\u2019RE LOOKING FOR\n\nCore Skills & Experience\n\n - Strong portfolio demonstrating end-to-end product design for technical or data-driven tools.\n\n - Proficiency in Figma, and fluency in systems design, UX architecture, and visual hierarchy.\n\n - Experience designing for developers, researchers, or technical domains \u2014 dashboards, APIs, model tooling, or infra products.\n\n - Familiarity with AI/ML concepts (training, evaluation, RL, fine-tuning) and comfort engaging with engineers on these topics.\n\n - Fundamental understanding of front-end principles (HTML, CSS, JS a plus)\n\n\nNice to Have\n\n - Prior experience designing ML research tools, IDEs, or developer platforms.\n\n - Comfort doing lightweight full-stack development to implement designs\n\n\n\nWHAT WE OFFER\n\n - Competitive compensation with significant equity incentives\n\n - Remote-first with a San Francisco hub\n\n - Budget for tools, software, and experimental projects\n\n - Opportunities to attend and shape AI/tech conferences\n\n - A chance to define the aesthetics of the decentralized AGI era\n\nIf you see design as more than visuals\u2014if you shape experiences, interfaces, and systems with precision and intent\u2014we want to build with you.\n\nReady to craft the future of AI? Apply now.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}], "apiVersion": "1"}