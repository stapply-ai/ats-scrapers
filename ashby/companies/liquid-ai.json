{"jobs": [{"id": "424e9e41-2848-4ed4-97dd-0f96ae530fdb", "title": "Member of Technical Staff - ML Research Engineer; Multi-Modal - Vision", "department": "Research & Engineering", "team": "Research & Engineering", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [{"location": "Boston", "address": {"postalAddress": {"addressRegion": "Massachusetts", "addressCountry": "United States", "addressLocality": "Cambridge"}}}], "publishedAt": "2025-10-23T20:05:18.636+00:00", "isListed": true, "isRemote": true, "address": {"postalAddress": {"addressRegion": "", "addressCountry": "United States", "addressLocality": ""}}, "jobUrl": "https://jobs.ashbyhq.com/liquid-ai/424e9e41-2848-4ed4-97dd-0f96ae530fdb", "applyUrl": "https://jobs.ashbyhq.com/liquid-ai/424e9e41-2848-4ed4-97dd-0f96ae530fdb/application", "descriptionHtml": "<h1><strong>Work With Us</strong></h1><p style=\"min-height:1.5em\">At Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.</p><p style=\"min-height:1.5em\">We believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.</p><p style=\"min-height:1.5em\"></p><h2><strong>This Role Is For You If:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">You have experience with machine learning at scale</p></li><li><p style=\"min-height:1.5em\">You\u2019re proficient in PyTorch, and familiar with distributed training frameworks like DeepSpeed, FSDP, or Megatron-LM</p></li><li><p style=\"min-height:1.5em\">You\u2019ve worked with multimodal data (e.g., image-text, video, visual documents, audio)</p></li><li><p style=\"min-height:1.5em\">You\u2019ve contributed to research papers, open-source projects, or production-grade multimodal model systems</p></li><li><p style=\"min-height:1.5em\">You understand how data quality, augmentations, and preprocessing pipelines can significantly impact model performance\u2014and you\u2019ve built tooling to support that</p></li><li><p style=\"min-height:1.5em\">You enjoy working in interdisciplinary teams across research, systems, and infrastructure, and can translate ideas into high-impact implementations</p></li></ul><h2><strong>Desired Experience:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">You\u2019ve designed and trained Vision Language Models</p></li><li><p style=\"min-height:1.5em\">You care deeply about empirical performance, and know how to design, run, and debug large-scale training experiments on distributed GPU clusters</p></li><li><p style=\"min-height:1.5em\">You\u2019ve developed vision encoders or integrated them into language pretraining pipelines with autoregressive or generative objectives</p></li><li><p style=\"min-height:1.5em\">You have experience working with large-scale video or document datasets, understand the unique challenges they pose, and can manage massive datasets effectively</p></li><li><p style=\"min-height:1.5em\">You\u2019ve built tools for data deduplication, image-text alignment, or vision tokenizer development</p></li></ul><h2><strong>What You'll Actually Do:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Investigate and prototype new model architectures that optimize inference speed, including on edge devices</p></li><li><p style=\"min-height:1.5em\">Lead or contribute to ablation studies and benchmark evaluations that inform architecture and data decisions</p></li><li><p style=\"min-height:1.5em\">Build and maintain evaluation suites for multimodal performance across a range of public and internal tasks</p></li><li><p style=\"min-height:1.5em\">Collaborate with the data and infrastructure teams to build scalable pipelines for ingesting and preprocessing large vision-language datasets</p></li><li><p style=\"min-height:1.5em\">Work with the infrastructure team to optimize model training across large-scale GPU clusters</p></li><li><p style=\"min-height:1.5em\">Contribute to publications, internal research documents, and thought leadership within the team and the broader ML community</p></li><li><p style=\"min-height:1.5em\">Collaborate with the applied research and business teams on client-specific use cases</p></li></ul><h2><strong>What You'll Gain:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">A front-row seat in building some of the most capable Vision Language Models</p></li><li><p style=\"min-height:1.5em\">Access to world-class infrastructure, a fast-moving research team, and deep collaboration across ML, systems, and product</p></li><li><p style=\"min-height:1.5em\">The opportunity to shape multimodal foundation model research with both scientific rigor and real-world impact</p></li></ul><p style=\"min-height:1.5em\"></p><h1><strong>About Liquid AI</strong></h1><p style=\"min-height:1.5em\">Spun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.</p>", "descriptionPlain": "WORK WITH US\n\nAt Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.\n\nWe believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.\n\n\nTHIS ROLE IS FOR YOU IF:\n\n - You have experience with machine learning at scale\n\n - You\u2019re proficient in PyTorch, and familiar with distributed training frameworks like DeepSpeed, FSDP, or Megatron-LM\n\n - You\u2019ve worked with multimodal data (e.g., image-text, video, visual documents, audio)\n\n - You\u2019ve contributed to research papers, open-source projects, or production-grade multimodal model systems\n\n - You understand how data quality, augmentations, and preprocessing pipelines can significantly impact model performance\u2014and you\u2019ve built tooling to support that\n\n - You enjoy working in interdisciplinary teams across research, systems, and infrastructure, and can translate ideas into high-impact implementations\n\n\nDESIRED EXPERIENCE:\n\n - You\u2019ve designed and trained Vision Language Models\n\n - You care deeply about empirical performance, and know how to design, run, and debug large-scale training experiments on distributed GPU clusters\n\n - You\u2019ve developed vision encoders or integrated them into language pretraining pipelines with autoregressive or generative objectives\n\n - You have experience working with large-scale video or document datasets, understand the unique challenges they pose, and can manage massive datasets effectively\n\n - You\u2019ve built tools for data deduplication, image-text alignment, or vision tokenizer development\n\n\nWHAT YOU'LL ACTUALLY DO:\n\n - Investigate and prototype new model architectures that optimize inference speed, including on edge devices\n\n - Lead or contribute to ablation studies and benchmark evaluations that inform architecture and data decisions\n\n - Build and maintain evaluation suites for multimodal performance across a range of public and internal tasks\n\n - Collaborate with the data and infrastructure teams to build scalable pipelines for ingesting and preprocessing large vision-language datasets\n\n - Work with the infrastructure team to optimize model training across large-scale GPU clusters\n\n - Contribute to publications, internal research documents, and thought leadership within the team and the broader ML community\n\n - Collaborate with the applied research and business teams on client-specific use cases\n\n\nWHAT YOU'LL GAIN:\n\n - A front-row seat in building some of the most capable Vision Language Models\n\n - Access to world-class infrastructure, a fast-moving research team, and deep collaboration across ML, systems, and product\n\n - The opportunity to shape multimodal foundation model research with both scientific rigor and real-world impact\n\n\nABOUT LIQUID AI\n\nSpun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "bd722889-13d9-4487-bd21-848ce2212905", "title": "Technical Recruiter", "department": "G&A", "team": "G&A", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [{"location": "Boston", "address": {"postalAddress": {"addressRegion": "Massachusetts", "addressCountry": "United States", "addressLocality": "Cambridge"}}}], "publishedAt": "2025-10-09T23:01:02.744+00:00", "isListed": true, "isRemote": true, "address": {"postalAddress": {"addressRegion": "", "addressCountry": "United States", "addressLocality": ""}}, "jobUrl": "https://jobs.ashbyhq.com/liquid-ai/bd722889-13d9-4487-bd21-848ce2212905", "applyUrl": "https://jobs.ashbyhq.com/liquid-ai/bd722889-13d9-4487-bd21-848ce2212905/application", "descriptionHtml": "<h1><strong>Work With Us</strong></h1><p style=\"min-height:1.5em\">At Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.</p><p style=\"min-height:1.5em\">We believe great talent is the ultimate performance multiplier. Behind every breakthrough model, system, and idea is a person who saw something others didn\u2019t. That\u2019s where this role comes in. You\u2019ll help us find, attract, and guide the world-class builders shaping the next generation of intelligence.</p><p style=\"min-height:1.5em\"></p><h2><strong>This Role Is For You If:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">You see recruiting as an act of deep understanding\u2014not just process, but perception.</p></li><li><p style=\"min-height:1.5em\">You can grok complex roles and decode what\u2019s <em>not</em> being said as easily as what is.</p></li><li><p style=\"min-height:1.5em\">You know how to coach hiring managers through the market\u2014balancing data, intuition, and empathy.</p></li><li><p style=\"min-height:1.5em\">You care about quality over volume and storytelling over spam.</p></li><li><p style=\"min-height:1.5em\">You take pride in building talent engines that scale without losing humanity.</p></li><li><p style=\"min-height:1.5em\">You bring clarity and confidence to high-profile people making high-stakes decisions.</p></li></ul><h2><strong>Desired Experience:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Proven track record of hiring for deeply technical or complex roles.</p></li><li><p style=\"min-height:1.5em\">Experience partnering with senior leaders to shape hiring strategies and narratives.</p></li><li><p style=\"min-height:1.5em\">Strong understanding of candidate psychology\u2014what drives, blocks, and converts top talent.</p></li><li><p style=\"min-height:1.5em\">Skilled at crafting messaging that actually sound human and inspires action</p></li><li><p style=\"min-height:1.5em\">Ability to move fluidly between strategy and execution\u2014comfortable in ambiguity.</p></li><li><p style=\"min-height:1.5em\">A genuine interest in technology, product, and the intersection between people and performance.</p></li></ul><h2><strong>What You'll Actually Do:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Coach and guide hiring managers on market realities, available talent, and smart tradeoffs.</p></li><li><p style=\"min-height:1.5em\">Discern complex roles to translate technical nuance into compelling, accurate storytelling.</p></li><li><p style=\"min-height:1.5em\">Build comprehensive, differentiated job descriptions and outreach campaigns that cut through noise.</p></li><li><p style=\"min-height:1.5em\">Deliver precise, high-quality candidate profiles that go beyond skillsets\u2014capturing motivation, mindset, and cultural fit.</p></li><li><p style=\"min-height:1.5em\">Guide high-profile candidates through a process that feels curated, considered, and distinctly Liquid.</p></li><li><p style=\"min-height:1.5em\">Partner with Talent Ops to help build a scalable, data-informed hiring engine that strengthens over time.</p></li><li><p style=\"min-height:1.5em\">Help shape the standards for what \u201cgreat\u201d looks like across every part of Liquid\u2019s hiring journey.</p></li></ul><h2><strong>What You'll Gain:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">A front-row seat in one of the most ambitious AI companies in the world.</p></li><li><p style=\"min-height:1.5em\">Direct collaboration with senior leadership, founders, and top-tier engineers and researchers.</p></li><li><p style=\"min-height:1.5em\">A chance to design how excellence in hiring actually works at scale.</p></li><li><p style=\"min-height:1.5em\">The freedom to innovate on process, storytelling, and experience\u2014while building something enduring.</p></li></ul><p style=\"min-height:1.5em\"></p><h1><strong>About Liquid AI</strong></h1><p style=\"min-height:1.5em\">Spun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.</p>", "descriptionPlain": "WORK WITH US\n\nAt Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.\n\nWe believe great talent is the ultimate performance multiplier. Behind every breakthrough model, system, and idea is a person who saw something others didn\u2019t. That\u2019s where this role comes in. You\u2019ll help us find, attract, and guide the world-class builders shaping the next generation of intelligence.\n\n\nTHIS ROLE IS FOR YOU IF:\n\n - You see recruiting as an act of deep understanding\u2014not just process, but perception.\n\n - You can grok complex roles and decode what\u2019s not being said as easily as what is.\n\n - You know how to coach hiring managers through the market\u2014balancing data, intuition, and empathy.\n\n - You care about quality over volume and storytelling over spam.\n\n - You take pride in building talent engines that scale without losing humanity.\n\n - You bring clarity and confidence to high-profile people making high-stakes decisions.\n\n\nDESIRED EXPERIENCE:\n\n - Proven track record of hiring for deeply technical or complex roles.\n\n - Experience partnering with senior leaders to shape hiring strategies and narratives.\n\n - Strong understanding of candidate psychology\u2014what drives, blocks, and converts top talent.\n\n - Skilled at crafting messaging that actually sound human and inspires action\n\n - Ability to move fluidly between strategy and execution\u2014comfortable in ambiguity.\n\n - A genuine interest in technology, product, and the intersection between people and performance.\n\n\nWHAT YOU'LL ACTUALLY DO:\n\n - Coach and guide hiring managers on market realities, available talent, and smart tradeoffs.\n\n - Discern complex roles to translate technical nuance into compelling, accurate storytelling.\n\n - Build comprehensive, differentiated job descriptions and outreach campaigns that cut through noise.\n\n - Deliver precise, high-quality candidate profiles that go beyond skillsets\u2014capturing motivation, mindset, and cultural fit.\n\n - Guide high-profile candidates through a process that feels curated, considered, and distinctly Liquid.\n\n - Partner with Talent Ops to help build a scalable, data-informed hiring engine that strengthens over time.\n\n - Help shape the standards for what \u201cgreat\u201d looks like across every part of Liquid\u2019s hiring journey.\n\n\nWHAT YOU'LL GAIN:\n\n - A front-row seat in one of the most ambitious AI companies in the world.\n\n - Direct collaboration with senior leadership, founders, and top-tier engineers and researchers.\n\n - A chance to design how excellence in hiring actually works at scale.\n\n - The freedom to innovate on process, storytelling, and experience\u2014while building something enduring.\n\n\nABOUT LIQUID AI\n\nSpun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "70e560dd-e153-4a5b-a827-837b0459ef9f", "title": "Member of Technical Staff - Applied ML Engineer", "department": "Research & Engineering", "team": "Research & Engineering", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [{"location": "Boston", "address": {"postalAddress": {"addressRegion": "Massachusetts", "addressCountry": "United States", "addressLocality": "Cambridge"}}}], "publishedAt": "2025-07-30T16:42:31.948+00:00", "isListed": true, "isRemote": true, "address": {"postalAddress": {"addressRegion": "", "addressCountry": "United States", "addressLocality": ""}}, "jobUrl": "https://jobs.ashbyhq.com/liquid-ai/70e560dd-e153-4a5b-a827-837b0459ef9f", "applyUrl": "https://jobs.ashbyhq.com/liquid-ai/70e560dd-e153-4a5b-a827-837b0459ef9f/application", "descriptionHtml": "<h1><strong>Work With Us</strong></h1><p style=\"min-height:1.5em\">At Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.</p><p style=\"min-height:1.5em\">We believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.</p><p style=\"min-height:1.5em\"></p><h2><strong>This Role Is For You If:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">You have hands-on experience optimizing and deploying local LLMs - running models like Llama, Mistral or other open-source LLMs locally through tools like vLLM, Ollama or LM Studio</p></li><li><p style=\"min-height:1.5em\">You're passionate about customizing ML models to solve real customer problems - from fine-tuning foundation models to optimizing them for specific use cases, you know how to make models work for unique requirements</p></li><li><p style=\"min-height:1.5em\">You have a knack for lightweight ML deployment and can architect solutions that work efficiently in resource-constrained environments - whether that's optimizing inference on CPUs, working with limited memory budgets, or deploying to edge devices</p></li><li><p style=\"min-height:1.5em\">You have a sharp eye for data quality and know what makes data effective - able to spot ineffective patterns in sample data, help design targeted synthetic datasets, and craft prompts that unlock the full potential of foundation models for specific use cases</p></li></ul><h2><strong>Desired Experience:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">You have customized an existing product for a customer</p></li><li><p style=\"min-height:1.5em\">You're versatile across deployment scenarios - whether it's containerized cloud deployments, on-premise installations with strict security requirements, or optimized edge inference, you can make models work anywhere</p></li></ul><h2><strong>What You'll Actually Do:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Own the complete deployment journey - from model customization to serving infrastructure, ensuring our solutions work flawlessly in variable customer environments</p></li><li><p style=\"min-height:1.5em\">Deploy AI systems to solve use cases others can not - implementing solutions that push beyond base LFMs can deliver and redefine what's possible with our technology</p></li><li><p style=\"min-height:1.5em\">Work alongside our core engineering team to leverage and enhance our powerful toolkit of Liquid infrastructure</p></li></ul><h2><strong>What You'll Gain:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">The ability to shape how the world's most influential organizations adopt and deploy LFMs - you'll be hands-on building solutions for customers who are reimagining entire industries</p></li><li><p style=\"min-height:1.5em\">Own the complete journey of delivering ML solutions that matter - from model customization to deployment architecture to seeing your work drive real customer impact</p></li></ul><p style=\"min-height:1.5em\"></p><h1><strong>About Liquid AI</strong></h1><p style=\"min-height:1.5em\">Spun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.</p>", "descriptionPlain": "WORK WITH US\n\nAt Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.\n\nWe believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.\n\n\nTHIS ROLE IS FOR YOU IF:\n\n - You have hands-on experience optimizing and deploying local LLMs - running models like Llama, Mistral or other open-source LLMs locally through tools like vLLM, Ollama or LM Studio\n\n - You're passionate about customizing ML models to solve real customer problems - from fine-tuning foundation models to optimizing them for specific use cases, you know how to make models work for unique requirements\n\n - You have a knack for lightweight ML deployment and can architect solutions that work efficiently in resource-constrained environments - whether that's optimizing inference on CPUs, working with limited memory budgets, or deploying to edge devices\n\n - You have a sharp eye for data quality and know what makes data effective - able to spot ineffective patterns in sample data, help design targeted synthetic datasets, and craft prompts that unlock the full potential of foundation models for specific use cases\n\n\nDESIRED EXPERIENCE:\n\n - You have customized an existing product for a customer\n\n - You're versatile across deployment scenarios - whether it's containerized cloud deployments, on-premise installations with strict security requirements, or optimized edge inference, you can make models work anywhere\n\n\nWHAT YOU'LL ACTUALLY DO:\n\n - Own the complete deployment journey - from model customization to serving infrastructure, ensuring our solutions work flawlessly in variable customer environments\n\n - Deploy AI systems to solve use cases others can not - implementing solutions that push beyond base LFMs can deliver and redefine what's possible with our technology\n\n - Work alongside our core engineering team to leverage and enhance our powerful toolkit of Liquid infrastructure\n\n\nWHAT YOU'LL GAIN:\n\n - The ability to shape how the world's most influential organizations adopt and deploy LFMs - you'll be hands-on building solutions for customers who are reimagining entire industries\n\n - Own the complete journey of delivering ML solutions that matter - from model customization to deployment architecture to seeing your work drive real customer impact\n\n\nABOUT LIQUID AI\n\nSpun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "f4245663-6a2f-4d47-bbd7-407ac9a9b2eb", "title": "Member of Technical Staff - Applied ML Lead ", "department": "Research & Engineering", "team": "Research & Engineering", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [{"location": "Boston", "address": {"postalAddress": {"addressRegion": "Massachusetts", "addressCountry": "United States", "addressLocality": "Cambridge"}}}], "publishedAt": "2025-08-26T20:27:26.677+00:00", "isListed": true, "isRemote": true, "address": {"postalAddress": {"addressRegion": "", "addressCountry": "United States", "addressLocality": ""}}, "jobUrl": "https://jobs.ashbyhq.com/liquid-ai/f4245663-6a2f-4d47-bbd7-407ac9a9b2eb", "applyUrl": "https://jobs.ashbyhq.com/liquid-ai/f4245663-6a2f-4d47-bbd7-407ac9a9b2eb/application", "descriptionHtml": "<h1><strong>Work With Us</strong></h1><p style=\"min-height:1.5em\">At Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.</p><p style=\"min-height:1.5em\">We believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.</p><p style=\"min-height:1.5em\"></p><h2><strong>This Role Is For You If:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">You enjoy spearheading customer engagements and orchestrating our implementation of Liquid Foundation Models (LFMs) to bridge the gap between customer needs and technical implementation</p></li><li><p style=\"min-height:1.5em\">You thrive at the intersection of deep technical expertise and strategic leadership; decoding customer challenges, architecting technical solutions, and leading our engineering team through flawless execution</p></li><li><p style=\"min-height:1.5em\">You're comfortable making technical decisions with incomplete information, guiding teams through ambiguity, and being the definitive technical voice for our customers</p></li></ul><h2><strong>Desired Experience:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">You have deep experience leading technical ML implementations with enterprise customers, including requirements gathering, solution design, and delivery management</p></li><li><p style=\"min-height:1.5em\">You possess deep technical knowledge of foundation models with hands-on experience in customization, fine-tuning, and deployment strategies</p></li><li><p style=\"min-height:1.5em\">You excel at distilling ambiguous customer problems into clear technical specifications that can be executed by implementation teams</p></li><li><p style=\"min-height:1.5em\">You can effectively communicate complex technical concepts to both technical and non-technical stakeholders, serving as the primary technical liaison with customers</p></li><li><p style=\"min-height:1.5em\">You have a proven track record of leading cross-functional teams to deliver complex ML solutions on time and to specification</p></li></ul><h2><strong>What You'll Actually Do:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Own end-to-end customer relationships from technical discovery through implementation and success validation</p></li><li><p style=\"min-height:1.5em\">Translate customer use cases into detailed technical implementation plans for the Applied ML Engineering team</p></li><li><p style=\"min-height:1.5em\">Conduct technical discovery sessions with customers to deeply understand their requirements, constraints, and success criteria</p></li><li><p style=\"min-height:1.5em\">Build and maintain the technical roadmap for each customer engagement, identifying risks and dependencies early</p></li><li><p style=\"min-height:1.5em\">Serve as the escalation point for complex technical challenges encountered during implementations</p></li><li><p style=\"min-height:1.5em\">Collaborate with product and engineering teams to align customer needs with our product roadmap</p></li><li><p style=\"min-height:1.5em\">Develop reusable implementation patterns and technical assets that accelerate future customer engagements</p></li></ul><h2><strong>What You'll Gain:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">The opportunity to define how cutting-edge LFM technology transforms businesses across industries</p></li><li><p style=\"min-height:1.5em\">Leadership experience building a high-performing technical implementation function from the ground up</p></li><li><p style=\"min-height:1.5em\">Visibility across the entire customer lifecycle, from initial engagement through successful deployment</p></li><li><p style=\"min-height:1.5em\">The satisfaction of seeing your technical vision translated into tangible customer outcomes that redefine what's possible with foundation models</p></li></ul><p style=\"min-height:1.5em\"></p><h1><strong>About Liquid AI</strong></h1><p style=\"min-height:1.5em\">Spun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.</p>", "descriptionPlain": "WORK WITH US\n\nAt Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.\n\nWe believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.\n\n\nTHIS ROLE IS FOR YOU IF:\n\n - You enjoy spearheading customer engagements and orchestrating our implementation of Liquid Foundation Models (LFMs) to bridge the gap between customer needs and technical implementation\n\n - You thrive at the intersection of deep technical expertise and strategic leadership; decoding customer challenges, architecting technical solutions, and leading our engineering team through flawless execution\n\n - You're comfortable making technical decisions with incomplete information, guiding teams through ambiguity, and being the definitive technical voice for our customers\n\n\nDESIRED EXPERIENCE:\n\n - You have deep experience leading technical ML implementations with enterprise customers, including requirements gathering, solution design, and delivery management\n\n - You possess deep technical knowledge of foundation models with hands-on experience in customization, fine-tuning, and deployment strategies\n\n - You excel at distilling ambiguous customer problems into clear technical specifications that can be executed by implementation teams\n\n - You can effectively communicate complex technical concepts to both technical and non-technical stakeholders, serving as the primary technical liaison with customers\n\n - You have a proven track record of leading cross-functional teams to deliver complex ML solutions on time and to specification\n\n\nWHAT YOU'LL ACTUALLY DO:\n\n - Own end-to-end customer relationships from technical discovery through implementation and success validation\n\n - Translate customer use cases into detailed technical implementation plans for the Applied ML Engineering team\n\n - Conduct technical discovery sessions with customers to deeply understand their requirements, constraints, and success criteria\n\n - Build and maintain the technical roadmap for each customer engagement, identifying risks and dependencies early\n\n - Serve as the escalation point for complex technical challenges encountered during implementations\n\n - Collaborate with product and engineering teams to align customer needs with our product roadmap\n\n - Develop reusable implementation patterns and technical assets that accelerate future customer engagements\n\n\nWHAT YOU'LL GAIN:\n\n - The opportunity to define how cutting-edge LFM technology transforms businesses across industries\n\n - Leadership experience building a high-performing technical implementation function from the ground up\n\n - Visibility across the entire customer lifecycle, from initial engagement through successful deployment\n\n - The satisfaction of seeing your technical vision translated into tangible customer outcomes that redefine what's possible with foundation models\n\n\nABOUT LIQUID AI\n\nSpun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "03b3da5d-0f1d-43c6-bdaa-561a123f37ea", "title": "Member of Technical Staff - Applied ML Scientist", "department": "Research & Engineering", "team": "Research & Engineering", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [{"location": "Boston", "address": {"postalAddress": {"addressRegion": "Massachusetts", "addressCountry": "United States", "addressLocality": "Cambridge"}}}], "publishedAt": "2025-08-26T20:40:20.150+00:00", "isListed": true, "isRemote": true, "address": {"postalAddress": {"addressRegion": "", "addressCountry": "United States", "addressLocality": ""}}, "jobUrl": "https://jobs.ashbyhq.com/liquid-ai/03b3da5d-0f1d-43c6-bdaa-561a123f37ea", "applyUrl": "https://jobs.ashbyhq.com/liquid-ai/03b3da5d-0f1d-43c6-bdaa-561a123f37ea/application", "descriptionHtml": "<h1><strong>Work With Us</strong></h1><p style=\"min-height:1.5em\">At Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.</p><p style=\"min-height:1.5em\">We believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.</p><p style=\"min-height:1.5em\"></p><h2><strong>This Role Is For You If:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">You thrive in high-autonomy, high-context environments and know how to turn vague questions into concrete experiments</p></li><li><p style=\"min-height:1.5em\">You\u2019ve worked on foundation models beyond just LLMs, and you understand the nuances of designing for real-world signals and feedback</p></li><li><p style=\"min-height:1.5em\">You\u2019re comfortable creating new training setups, loss functions, or evaluation methods tailored to customer-specific metrics</p></li><li><p style=\"min-height:1.5em\">You have deep experience with the PyTorch ecosystem (including distributed training and third-party libraries), and can move quickly from prototype to production-scale experiments</p></li><li><p style=\"min-height:1.5em\">You\u2019re energized by tight feedback loops with customers and believe that experimentation should be aligned with product objectives</p></li><li><p style=\"min-height:1.5em\">You can think at multiple altitudes\u2014from quick-turn tests to longer-term architecture bets\u2014and know when to scale each</p></li></ul><h2><strong>What You'll Actually Do:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Own the end-to-end experimental process: from hypothesis generation to results analysis to iteration</p></li><li><p style=\"min-height:1.5em\">Design and run structured experiments to evaluate model performance across customer-specific metrics</p></li><li><p style=\"min-height:1.5em\">Develop tooling and workflows that let the team rapidly test hypotheses and scale promising directions</p></li><li><p style=\"min-height:1.5em\">Work closely with research, infra, and customer teams to prioritize experimental goals and interpret results</p></li><li><p style=\"min-height:1.5em\">Translate customer needs into actionable model improvements via principled experimentation</p></li><li><p style=\"min-height:1.5em\">Contribute to building a culture of fast, reproducible, and product-aligned model research</p></li></ul><h2><strong>What You'll Gain:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Lead high-leverage experimentation at the intersection of foundational model research and real-world customer impact</p></li><li><p style=\"min-height:1.5em\">Hands-on, research-driven role where you'll own the end-to-end lifecycle of designing, running, and analyzing experiments that push forward our hybrid model systems</p></li><li><p style=\"min-height:1.5em\">Your work will directly shape how our models perform in customer contexts, with an emphasis on measurable impact over theoretical gains</p></li><li><p style=\"min-height:1.5em\">You\u2019ll collaborate closely with infra, modeling, and customer teams to ensure that experimental insights are actionable and aligned with product goals</p></li></ul><p style=\"min-height:1.5em\"></p><h1><strong>About Liquid AI</strong></h1><p style=\"min-height:1.5em\">Spun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.</p>", "descriptionPlain": "WORK WITH US\n\nAt Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.\n\nWe believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.\n\n\nTHIS ROLE IS FOR YOU IF:\n\n - You thrive in high-autonomy, high-context environments and know how to turn vague questions into concrete experiments\n\n - You\u2019ve worked on foundation models beyond just LLMs, and you understand the nuances of designing for real-world signals and feedback\n\n - You\u2019re comfortable creating new training setups, loss functions, or evaluation methods tailored to customer-specific metrics\n\n - You have deep experience with the PyTorch ecosystem (including distributed training and third-party libraries), and can move quickly from prototype to production-scale experiments\n\n - You\u2019re energized by tight feedback loops with customers and believe that experimentation should be aligned with product objectives\n\n - You can think at multiple altitudes\u2014from quick-turn tests to longer-term architecture bets\u2014and know when to scale each\n\n\nWHAT YOU'LL ACTUALLY DO:\n\n - Own the end-to-end experimental process: from hypothesis generation to results analysis to iteration\n\n - Design and run structured experiments to evaluate model performance across customer-specific metrics\n\n - Develop tooling and workflows that let the team rapidly test hypotheses and scale promising directions\n\n - Work closely with research, infra, and customer teams to prioritize experimental goals and interpret results\n\n - Translate customer needs into actionable model improvements via principled experimentation\n\n - Contribute to building a culture of fast, reproducible, and product-aligned model research\n\n\nWHAT YOU'LL GAIN:\n\n - Lead high-leverage experimentation at the intersection of foundational model research and real-world customer impact\n\n - Hands-on, research-driven role where you'll own the end-to-end lifecycle of designing, running, and analyzing experiments that push forward our hybrid model systems\n\n - Your work will directly shape how our models perform in customer contexts, with an emphasis on measurable impact over theoretical gains\n\n - You\u2019ll collaborate closely with infra, modeling, and customer teams to ensure that experimental insights are actionable and aligned with product goals\n\n\nABOUT LIQUID AI\n\nSpun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "1dddcdd1-c396-428f-87e0-4cec97586d48", "title": "Member of GTM Team - Strategic Partnerships", "department": "GTM", "team": "GTM", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [{"location": "Boston", "address": {"postalAddress": {"addressRegion": "Massachusetts", "addressCountry": "United States", "addressLocality": "Cambridge"}}}], "publishedAt": "2025-08-22T19:20:20.802+00:00", "isListed": true, "isRemote": true, "address": {"postalAddress": {"addressRegion": "", "addressCountry": "United States", "addressLocality": ""}}, "jobUrl": "https://jobs.ashbyhq.com/liquid-ai/1dddcdd1-c396-428f-87e0-4cec97586d48", "applyUrl": "https://jobs.ashbyhq.com/liquid-ai/1dddcdd1-c396-428f-87e0-4cec97586d48/application", "descriptionHtml": "<h2>Work With Us</h2><p style=\"min-height:1.5em\">At Liquid, we\u2019re not just building AI models \u2014 we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas \u2014 we\u2019re architecting what comes next.</p><p style=\"min-height:1.5em\">We believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and business leaders creating the next generation of AI. Whether you\u2019re building foundational architectures, forging pivotal partnerships, or driving enterprise adoption \u2014 your work will directly shape the future of intelligent systems.</p><p style=\"min-height:1.5em\"></p><h2><strong>This Role Is For You If:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">You\u2019re a proven player-coach with the executive judgment, commercial instinct, and technical intuition to lead Liquid\u2019s most critical strategic partnerships</p></li><li><p style=\"min-height:1.5em\">You excel at navigating high-ambiguity, high-stakes conversations and can operate autonomously while representing the company at the highest levels</p></li><li><p style=\"min-height:1.5em\">You have a rare blend of technical fluency, commercial creativity, and executive polish, enabling you to move seamlessly between technical teams, C-suites, and commercial negotiations</p></li><li><p style=\"min-height:1.5em\">You can understand how foundation models create leverage for enterprise partners and know how to navigate internal dynamics to make complex deals happen</p></li><li><p style=\"min-height:1.5em\">You\u2019re relentless in execution \u2014 able to simplify the complex, craft bespoke deal structures, and deliver measurable outcomes</p></li></ul><h2><strong>Desired Experience:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Strong experience across enterprise partnerships, business development, corporate development, or equivalent \u2014 ideally in AI, semiconductors, or infrastructure</p></li><li><p style=\"min-height:1.5em\">Proven experience leading go-to-market strategies across channel, distribution, and reseller networks, as well as managing licensing partnerships</p></li><li><p style=\"min-height:1.5em\">Demonstrated ability to architect and negotiate complex partnership agreements in collaboration with Legal and Finance</p></li><li><p style=\"min-height:1.5em\">Track record of mentoring and building high-performing partnerships teams, with an eye toward scalable processes and repeatable success</p></li></ul><h2><strong>What You\u2019ll Actually Do:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Develop and manage a portfolio of strategic partners aligned with Liquid\u2019s objectives and long-term vision</p></li><li><p style=\"min-height:1.5em\">Own the partnership roadmap with clear milestones, timelines, and success metrics (adoption, revenue, product launches)</p></li><li><p style=\"min-height:1.5em\">Architect and execute bespoke partnership structures across commercial, technical, and strategic dimensions</p></li><li><p style=\"min-height:1.5em\">Serve as a trusted thought partner to the Head of Business and executive leadership.</p></li><li><p style=\"min-height:1.5em\">Map and influence key stakeholders across product, corporate development, procurement, and technical teams to drive aligned outcomes</p></li><li><p style=\"min-height:1.5em\">Negotiate complex, multi-dimensional agreements with top-tier partners</p></li><li><p style=\"min-height:1.5em\">Provide mentorship and guidance to junior team members while implementing scalable, repeatable partnership processes</p></li></ul><h2><strong>What You\u2019ll Gain:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">A seat at the table in shaping the partnerships strategy for one of the most ambitious AI companies in the world</p></li><li><p style=\"min-height:1.5em\">The ability to forge alliances with leading global enterprises, hardware OEMs, and cloud/model providers \u2014 relationships that will directly influence Liquid\u2019s trajectory</p></li><li><p style=\"min-height:1.5em\">The opportunity to build and mentor a world-class partnerships function from the ground up</p><p style=\"min-height:1.5em\"></p></li></ul><h2>About Liquid AI</h2><p style=\"min-height:1.5em\">Spun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale \u2014 from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.</p>", "descriptionPlain": "WORK WITH US\n\nAt Liquid, we\u2019re not just building AI models \u2014 we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas \u2014 we\u2019re architecting what comes next.\n\nWe believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and business leaders creating the next generation of AI. Whether you\u2019re building foundational architectures, forging pivotal partnerships, or driving enterprise adoption \u2014 your work will directly shape the future of intelligent systems.\n\n\nTHIS ROLE IS FOR YOU IF:\n\n - You\u2019re a proven player-coach with the executive judgment, commercial instinct, and technical intuition to lead Liquid\u2019s most critical strategic partnerships\n\n - You excel at navigating high-ambiguity, high-stakes conversations and can operate autonomously while representing the company at the highest levels\n\n - You have a rare blend of technical fluency, commercial creativity, and executive polish, enabling you to move seamlessly between technical teams, C-suites, and commercial negotiations\n\n - You can understand how foundation models create leverage for enterprise partners and know how to navigate internal dynamics to make complex deals happen\n\n - You\u2019re relentless in execution \u2014 able to simplify the complex, craft bespoke deal structures, and deliver measurable outcomes\n\n\nDESIRED EXPERIENCE:\n\n - Strong experience across enterprise partnerships, business development, corporate development, or equivalent \u2014 ideally in AI, semiconductors, or infrastructure\n\n - Proven experience leading go-to-market strategies across channel, distribution, and reseller networks, as well as managing licensing partnerships\n\n - Demonstrated ability to architect and negotiate complex partnership agreements in collaboration with Legal and Finance\n\n - Track record of mentoring and building high-performing partnerships teams, with an eye toward scalable processes and repeatable success\n\n\nWHAT YOU\u2019LL ACTUALLY DO:\n\n - Develop and manage a portfolio of strategic partners aligned with Liquid\u2019s objectives and long-term vision\n\n - Own the partnership roadmap with clear milestones, timelines, and success metrics (adoption, revenue, product launches)\n\n - Architect and execute bespoke partnership structures across commercial, technical, and strategic dimensions\n\n - Serve as a trusted thought partner to the Head of Business and executive leadership.\n\n - Map and influence key stakeholders across product, corporate development, procurement, and technical teams to drive aligned outcomes\n\n - Negotiate complex, multi-dimensional agreements with top-tier partners\n\n - Provide mentorship and guidance to junior team members while implementing scalable, repeatable partnership processes\n\n\nWHAT YOU\u2019LL GAIN:\n\n - A seat at the table in shaping the partnerships strategy for one of the most ambitious AI companies in the world\n\n - The ability to forge alliances with leading global enterprises, hardware OEMs, and cloud/model providers \u2014 relationships that will directly influence Liquid\u2019s trajectory\n\n - The opportunity to build and mentor a world-class partnerships function from the ground up\n\n\nABOUT LIQUID AI\n\nSpun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale \u2014 from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "f8839590-138f-489f-ac2d-8b6a9e0bcef7", "title": "Member of Technical Staff - ML Engineer / Scientist (JP Localization)", "department": "Research & Engineering", "team": "Research & Engineering", "employmentType": "FullTime", "location": "Tokyo", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [], "publishedAt": "2025-09-29T04:06:49.746+00:00", "isListed": true, "isRemote": true, "address": {"postalAddress": {"addressRegion": "Tokyo", "addressCountry": "Japan", "addressLocality": "Tokyo"}}, "jobUrl": "https://jobs.ashbyhq.com/liquid-ai/f8839590-138f-489f-ac2d-8b6a9e0bcef7", "applyUrl": "https://jobs.ashbyhq.com/liquid-ai/f8839590-138f-489f-ac2d-8b6a9e0bcef7/application", "descriptionHtml": "<h1><strong>Work With Us</strong></h1><p style=\"min-height:1.5em\">At Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.</p><p style=\"min-height:1.5em\">We believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.</p><p style=\"min-height:1.5em\"></p><h2><strong>This Role Is For You If:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">You like building LLM pipelines and agents for diverse use cases, and enjoy catching and fixing edge cases where LLMs may fail</p></li><li><p style=\"min-height:1.5em\">You\u2019re a native Japanese speaker and want to further improve LLM capabilities in Japanese</p></li><li><p style=\"min-height:1.5em\">You\u2019re motivated by the challenge of adapting foundation models to new languages, cultures, and enterprise workflows</p></li></ul><h2><strong>Desired Experience:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Deep understanding of the Japanese model evaluation landscape and familiarity with Japanese pre-training data sources</p></li><li><p style=\"min-height:1.5em\">Experience using modeling and inference tools such as Huggingface inference, vLLM, and cloud APIs</p></li></ul><h2><strong>What You'll Actually Do:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Identify, collect, and curate diverse high-quality Japanese text, audio, and multimodal datasets</p></li><li><p style=\"min-height:1.5em\">Design methods to synthetically generate or augment Japanese training data when needed</p></li><li><p style=\"min-height:1.5em\">Ensure datasets meet enterprise-grade quality, coverage, and compliance requirements</p></li><li><p style=\"min-height:1.5em\">Train and fine-tune language and vision models to achieve state-of-the-art performance for Japanese enterprise use cases</p></li><li><p style=\"min-height:1.5em\">Adapt existing LFMs for Japanese language, culture, and enterprise-specific workflows</p></li><li><p style=\"min-height:1.5em\">Implement evaluation frameworks to benchmark model quality on Japanese datasets</p></li><li><p style=\"min-height:1.5em\">Design evaluation datasets and metrics for Japanese enterprise applications</p></li><li><p style=\"min-height:1.5em\">Conduct thorough error analysis and iteratively improve model performance</p></li><li><p style=\"min-height:1.5em\">Ensure robustness, fairness, and reliability in Japanese-language outputs</p></li></ul><h2><strong>What You'll Gain:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Hands-on experience with state-of-the-art technology at a leading AI company</p></li><li><p style=\"min-height:1.5em\">The opportunity to directly shape foundation model performance in one of the world\u2019s most complex and nuanced languages</p></li><li><p style=\"min-height:1.5em\">A collaborative, fast-paced environment where your work drives the next generation of LFMs</p></li></ul><p style=\"min-height:1.5em\"></p><h1><strong>About Liquid AI</strong></h1><p style=\"min-height:1.5em\">Spun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.</p>", "descriptionPlain": "WORK WITH US\n\nAt Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.\n\nWe believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.\n\n\nTHIS ROLE IS FOR YOU IF:\n\n - You like building LLM pipelines and agents for diverse use cases, and enjoy catching and fixing edge cases where LLMs may fail\n\n - You\u2019re a native Japanese speaker and want to further improve LLM capabilities in Japanese\n\n - You\u2019re motivated by the challenge of adapting foundation models to new languages, cultures, and enterprise workflows\n\n\nDESIRED EXPERIENCE:\n\n - Deep understanding of the Japanese model evaluation landscape and familiarity with Japanese pre-training data sources\n\n - Experience using modeling and inference tools such as Huggingface inference, vLLM, and cloud APIs\n\n\nWHAT YOU'LL ACTUALLY DO:\n\n - Identify, collect, and curate diverse high-quality Japanese text, audio, and multimodal datasets\n\n - Design methods to synthetically generate or augment Japanese training data when needed\n\n - Ensure datasets meet enterprise-grade quality, coverage, and compliance requirements\n\n - Train and fine-tune language and vision models to achieve state-of-the-art performance for Japanese enterprise use cases\n\n - Adapt existing LFMs for Japanese language, culture, and enterprise-specific workflows\n\n - Implement evaluation frameworks to benchmark model quality on Japanese datasets\n\n - Design evaluation datasets and metrics for Japanese enterprise applications\n\n - Conduct thorough error analysis and iteratively improve model performance\n\n - Ensure robustness, fairness, and reliability in Japanese-language outputs\n\n\nWHAT YOU'LL GAIN:\n\n - Hands-on experience with state-of-the-art technology at a leading AI company\n\n - The opportunity to directly shape foundation model performance in one of the world\u2019s most complex and nuanced languages\n\n - A collaborative, fast-paced environment where your work drives the next generation of LFMs\n\n\nABOUT LIQUID AI\n\nSpun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "c7251e1b-d7bf-4d03-8b9e-1382743bef2c", "title": "Member of Technical Staff - ML Research Engineer, Foundation Model Data", "department": "Research & Engineering", "team": "Research & Engineering", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [{"location": "Boston", "address": {"postalAddress": {"addressRegion": "Massachusetts", "addressCountry": "United States", "addressLocality": "Cambridge"}}}, {"location": "Remote", "address": {"postalAddress": {"addressCountry": "Remote"}}}], "publishedAt": "2025-07-29T23:40:48.795+00:00", "isListed": true, "isRemote": true, "address": {"postalAddress": {"addressRegion": "", "addressCountry": "United States", "addressLocality": ""}}, "jobUrl": "https://jobs.ashbyhq.com/liquid-ai/c7251e1b-d7bf-4d03-8b9e-1382743bef2c", "applyUrl": "https://jobs.ashbyhq.com/liquid-ai/c7251e1b-d7bf-4d03-8b9e-1382743bef2c/application", "descriptionHtml": "<h1><strong>Work With Us</strong></h1><p style=\"min-height:1.5em\">At Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.</p><p style=\"min-height:1.5em\">We believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.</p><p style=\"min-height:1.5em\"></p><p style=\"min-height:1.5em\"><em><strong>While San Francisco and Boston are preferred, we are open to other locations.</strong></em></p><p style=\"min-height:1.5em\"></p><h2><strong>This Role Is For You If:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">You want to play a critical role in our foundation model development process, focusing on consolidating, gathering, and generating high-quality text data for pretraining, midtraining, SFT, and preference optimization</p></li></ul><h2><strong>Required Experience:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\"><strong>Experience Level:</strong> B.S. + 5 years experience or M.S. + 3 years experience or Ph.D. + 1 year of experience</p></li><li><p style=\"min-height:1.5em\"><strong>Dataset Engineering</strong>: Expertise in data curation, cleaning, augmentation, and synthetic data generation techniques</p></li><li><p style=\"min-height:1.5em\"><strong>Machine Learning Expertise:</strong> Ability to write and debug models in popular ML frameworks, and experience working with LLMs</p></li><li><p style=\"min-height:1.5em\"><strong>Software Development</strong>: Strong programming skills in Python, with an emphasis on writing clean, maintainable, and scalable code</p></li></ul><h2><strong>Desired Experience:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">M.S. or Ph.D. in Computer Science, Electrical Engineering, Math, or a related field.</p></li><li><p style=\"min-height:1.5em\">Experience fine-tuning or customizing LLMs</p></li><li><p style=\"min-height:1.5em\">First-author publications in top ML conferences (e.g. NeurIPS, ICML, ICLR).</p></li><li><p style=\"min-height:1.5em\">Contributions to popular open-source projects</p></li></ul><h2><strong>What You'll Actually Do:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Create and maintain data cleaning, filtering, selection pipeline than can handle &gt;100TB of data</p></li><li><p style=\"min-height:1.5em\">Watch out for the release of public dataset on huggingface and other platforms</p></li><li><p style=\"min-height:1.5em\">Create crawlers to gather datasets from the web where public data is lacking</p></li><li><p style=\"min-height:1.5em\">Write and maintain synthetic data generation pipelines</p></li><li><p style=\"min-height:1.5em\">Run ablations to assess new dataset and judging pipelines</p></li></ul><h2><strong>What You'll Gain:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Hands-on experience with state-of-the-art technology at a leading AI company</p></li><li><p style=\"min-height:1.5em\">A collaborative, fast-paced environment where your work directly shapes our products and the next generation of LFMs</p></li></ul><p style=\"min-height:1.5em\"></p><h1><strong>About Liquid AI</strong></h1><p style=\"min-height:1.5em\">Spun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.</p>", "descriptionPlain": "WORK WITH US\n\nAt Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.\n\nWe believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.\n\nWhile San Francisco and Boston are preferred, we are open to other locations.\n\n\nTHIS ROLE IS FOR YOU IF:\n\n - You want to play a critical role in our foundation model development process, focusing on consolidating, gathering, and generating high-quality text data for pretraining, midtraining, SFT, and preference optimization\n\n\nREQUIRED EXPERIENCE:\n\n - Experience Level: B.S. + 5 years experience or M.S. + 3 years experience or Ph.D. + 1 year of experience\n\n - Dataset Engineering: Expertise in data curation, cleaning, augmentation, and synthetic data generation techniques\n\n - Machine Learning Expertise: Ability to write and debug models in popular ML frameworks, and experience working with LLMs\n\n - Software Development: Strong programming skills in Python, with an emphasis on writing clean, maintainable, and scalable code\n\n\nDESIRED EXPERIENCE:\n\n - M.S. or Ph.D. in Computer Science, Electrical Engineering, Math, or a related field.\n\n - Experience fine-tuning or customizing LLMs\n\n - First-author publications in top ML conferences (e.g. NeurIPS, ICML, ICLR).\n\n - Contributions to popular open-source projects\n\n\nWHAT YOU'LL ACTUALLY DO:\n\n - Create and maintain data cleaning, filtering, selection pipeline than can handle >100TB of data\n\n - Watch out for the release of public dataset on huggingface and other platforms\n\n - Create crawlers to gather datasets from the web where public data is lacking\n\n - Write and maintain synthetic data generation pipelines\n\n - Run ablations to assess new dataset and judging pipelines\n\n\nWHAT YOU'LL GAIN:\n\n - Hands-on experience with state-of-the-art technology at a leading AI company\n\n - A collaborative, fast-paced environment where your work directly shapes our products and the next generation of LFMs\n\n\nABOUT LIQUID AI\n\nSpun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "dfc3bae5-003f-4438-b51a-4cdfdb4199ba", "title": "Member of Technical Staff - ML Research Engineer, Performance Optimization", "department": "Research & Engineering", "team": "Research & Engineering", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [{"location": "Boston", "address": {"postalAddress": {"addressRegion": "Massachusetts", "addressCountry": "United States", "addressLocality": "Cambridge"}}}, {"location": "Remote", "address": {"postalAddress": {"addressCountry": "Remote"}}}], "publishedAt": "2025-07-29T20:46:39.065+00:00", "isListed": true, "isRemote": true, "address": {"postalAddress": {"addressRegion": "", "addressCountry": "United States", "addressLocality": ""}}, "jobUrl": "https://jobs.ashbyhq.com/liquid-ai/dfc3bae5-003f-4438-b51a-4cdfdb4199ba", "applyUrl": "https://jobs.ashbyhq.com/liquid-ai/dfc3bae5-003f-4438-b51a-4cdfdb4199ba/application", "descriptionHtml": "<h1><strong>Work With Us</strong></h1><p style=\"min-height:1.5em\">At Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.</p><p style=\"min-height:1.5em\">We believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.</p><p style=\"min-height:1.5em\"></p><p style=\"min-height:1.5em\"><em><strong>While San Francisco and Boston are preferred, we are open to other locations.</strong></em></p><p style=\"min-height:1.5em\"></p><h2><strong>This Role Is For You If:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">You have experience writing high-performance, custom GPU kernels for training or inference</p></li><li><p style=\"min-height:1.5em\">You have an understanding of low-level profiling tools and how to tune kernels with such tools</p></li><li><p style=\"min-height:1.5em\">You have experience integrating GPU kernels into frameworks like PyTorch, bridging the gap between high-level models and low-level hardware performance</p></li><li><p style=\"min-height:1.5em\">You have a solid understanding of memory hierarchy and have optimized for compute and memory-bound workloads</p></li><li><p style=\"min-height:1.5em\">You have implemented fine-grain optimizations for a target hardware, e.g. targeting tensor cores</p></li></ul><h2><strong>Desired Experience:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">CUDA</p></li><li><p style=\"min-height:1.5em\">CUTLASS</p></li><li><p style=\"min-height:1.5em\">C/C++</p></li><li><p style=\"min-height:1.5em\">PyTorch/Triton</p></li></ul><h2><strong>What You'll Actually Do:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Write high-performance GPU kernels for inference workloads</p></li><li><p style=\"min-height:1.5em\">Optimize alternative architectures used at Liquid across all model parameter sizes</p></li><li><p style=\"min-height:1.5em\">Implement the latest techniques and ideas from research into low-level GPU kernels</p></li><li><p style=\"min-height:1.5em\">Continuously monitor, profile, and improve the performance of our inference pipelines</p></li></ul><h2><strong>What You'll Gain:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Hands-on experience with state-of-the-art technology at a leading AI company</p></li><li><p style=\"min-height:1.5em\">Deeper expertise in machine learning systems and performance optimization</p></li><li><p style=\"min-height:1.5em\">Opportunity to bridge the gap between theoretical improvements in research and effective gains in practice</p></li><li><p style=\"min-height:1.5em\">A collaborative, fast-paced environment where your work directly shapes our products and the next generation of LFMs</p></li></ul><p style=\"min-height:1.5em\"></p><h1><strong>About Liquid AI</strong></h1><p style=\"min-height:1.5em\">Spun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.</p>", "descriptionPlain": "WORK WITH US\n\nAt Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.\n\nWe believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.\n\nWhile San Francisco and Boston are preferred, we are open to other locations.\n\n\nTHIS ROLE IS FOR YOU IF:\n\n - You have experience writing high-performance, custom GPU kernels for training or inference\n\n - You have an understanding of low-level profiling tools and how to tune kernels with such tools\n\n - You have experience integrating GPU kernels into frameworks like PyTorch, bridging the gap between high-level models and low-level hardware performance\n\n - You have a solid understanding of memory hierarchy and have optimized for compute and memory-bound workloads\n\n - You have implemented fine-grain optimizations for a target hardware, e.g. targeting tensor cores\n\n\nDESIRED EXPERIENCE:\n\n - CUDA\n\n - CUTLASS\n\n - C/C++\n\n - PyTorch/Triton\n\n\nWHAT YOU'LL ACTUALLY DO:\n\n - Write high-performance GPU kernels for inference workloads\n\n - Optimize alternative architectures used at Liquid across all model parameter sizes\n\n - Implement the latest techniques and ideas from research into low-level GPU kernels\n\n - Continuously monitor, profile, and improve the performance of our inference pipelines\n\n\nWHAT YOU'LL GAIN:\n\n - Hands-on experience with state-of-the-art technology at a leading AI company\n\n - Deeper expertise in machine learning systems and performance optimization\n\n - Opportunity to bridge the gap between theoretical improvements in research and effective gains in practice\n\n - A collaborative, fast-paced environment where your work directly shapes our products and the next generation of LFMs\n\n\nABOUT LIQUID AI\n\nSpun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "69daadb4-f70e-4e31-b1ec-10d92e267fd3", "title": "Member of Technical Staff - DevRel", "department": "Research & Engineering", "team": "Research & Engineering", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [{"location": "Boston", "address": {"postalAddress": {"addressRegion": "Massachusetts", "addressCountry": "United States", "addressLocality": "Cambridge"}}}, {"location": "Remote", "address": {"postalAddress": {"addressCountry": "Remote"}}}], "publishedAt": "2025-07-29T22:58:07.160+00:00", "isListed": true, "isRemote": true, "address": {"postalAddress": {"addressRegion": "", "addressCountry": "United States", "addressLocality": ""}}, "jobUrl": "https://jobs.ashbyhq.com/liquid-ai/69daadb4-f70e-4e31-b1ec-10d92e267fd3", "applyUrl": "https://jobs.ashbyhq.com/liquid-ai/69daadb4-f70e-4e31-b1ec-10d92e267fd3/application", "descriptionHtml": "<h1><strong>Work With Us</strong></h1><p style=\"min-height:1.5em\">At Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.</p><p style=\"min-height:1.5em\">We believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.</p><p style=\"min-height:1.5em\"></p><p style=\"min-height:1.5em\"><em><strong>While San Francisco and Boston are preferred, we are open to other locations in United States.</strong></em></p><p style=\"min-height:1.5em\"><br /></p><h2><strong>This Role Is For You If:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">You obsess over impact, bring relentless care and craftsmanship to building things that truly matter to users</p></li><li><p style=\"min-height:1.5em\">You've shipped code that other developers actually use</p></li><li><p style=\"min-height:1.5em\">You can explain complex technical concepts without dumbing them down</p></li><li><p style=\"min-height:1.5em\">You have strong opinions about what makes foundation models actually useful vs just impressive</p></li><li><p style=\"min-height:1.5em\">You understand the difference between research demos and production-ready tools</p></li></ul><h2><strong>What You'll Actually Do:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Developer Experience: Everything from first API call to production deployment needs to feel effortless</p></li><li><p style=\"min-height:1.5em\">Technical Content: Demos, tutorials, and reference implementations that make our differentiation tangible</p></li><li><p style=\"min-height:1.5em\">Community Presence: Drive community impact, engagement and management through talks, writing, hackathons, and hands-on engagement wherever ML engineers shape the future. Bias for action essential</p></li><li><p style=\"min-height:1.5em\">Feedback Loop: Translating real developer friction back to our engineering teams</p></li><li><p style=\"min-height:1.5em\">Adoption Metrics: Moving the needle from \"interesting research\" to \"production workloads\"</p></li><li><p style=\"min-height:1.5em\">You'll be our first line of contact with the developer community, which means you're not just explaining what we've built \u2013 you're helping shape what we build next based on how people actually want to use it. The goal isn't just awareness. It's developers choosing us for their next project because the experience is genuinely better</p></li></ul><h2><strong>What You'll Gain:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Engagement with developers, manage community feedback loops, and champion insights that shape Liquid product</p></li><li><p style=\"min-height:1.5em\">Building integration examples that solve real problems developers face</p></li><li><p style=\"min-height:1.5em\">Writing documentation that assumes intelligence but not telepathy</p></li><li><p style=\"min-height:1.5em\">Representing our technical decisions at conferences and in technical forums</p></li><li><p style=\"min-height:1.5em\">Working directly with research teams to influence roadmap based on developer needs</p></li><li><p style=\"min-height:1.5em\">Creating content that demonstrates why our approach matters for production use cases<br /></p></li></ul><p style=\"min-height:1.5em\"><strong>About Liquid AI<br /><br /></strong>Spun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.</p>", "descriptionPlain": "WORK WITH US\n\nAt Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.\n\nWe believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.\n\nWhile San Francisco and Boston are preferred, we are open to other locations in United States.\n\n\n\n\n\nTHIS ROLE IS FOR YOU IF:\n\n - You obsess over impact, bring relentless care and craftsmanship to building things that truly matter to users\n\n - You've shipped code that other developers actually use\n\n - You can explain complex technical concepts without dumbing them down\n\n - You have strong opinions about what makes foundation models actually useful vs just impressive\n\n - You understand the difference between research demos and production-ready tools\n\n\nWHAT YOU'LL ACTUALLY DO:\n\n - Developer Experience: Everything from first API call to production deployment needs to feel effortless\n\n - Technical Content: Demos, tutorials, and reference implementations that make our differentiation tangible\n\n - Community Presence: Drive community impact, engagement and management through talks, writing, hackathons, and hands-on engagement wherever ML engineers shape the future. Bias for action essential\n\n - Feedback Loop: Translating real developer friction back to our engineering teams\n\n - Adoption Metrics: Moving the needle from \"interesting research\" to \"production workloads\"\n\n - You'll be our first line of contact with the developer community, which means you're not just explaining what we've built \u2013 you're helping shape what we build next based on how people actually want to use it. The goal isn't just awareness. It's developers choosing us for their next project because the experience is genuinely better\n\n\nWHAT YOU'LL GAIN:\n\n - Engagement with developers, manage community feedback loops, and champion insights that shape Liquid product\n\n - Building integration examples that solve real problems developers face\n\n - Writing documentation that assumes intelligence but not telepathy\n\n - Representing our technical decisions at conferences and in technical forums\n\n - Working directly with research teams to influence roadmap based on developer needs\n\n - Creating content that demonstrates why our approach matters for production use cases\n   \n\nAbout Liquid AI\n\nSpun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "fe8596ae-becc-49d2-a3dd-f68ed74144a0", "title": "Member of Technical Staff - ML Research Engineer, VLM Data", "department": "Research & Engineering", "team": "Research & Engineering", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [{"location": "Boston", "address": {"postalAddress": {"addressRegion": "Massachusetts", "addressCountry": "United States", "addressLocality": "Cambridge"}}}, {"location": "Remote", "address": {"postalAddress": {"addressCountry": "Remote"}}}], "publishedAt": "2025-08-28T20:54:51.275+00:00", "isListed": true, "isRemote": true, "address": {"postalAddress": {"addressRegion": "", "addressCountry": "United States", "addressLocality": ""}}, "jobUrl": "https://jobs.ashbyhq.com/liquid-ai/fe8596ae-becc-49d2-a3dd-f68ed74144a0", "applyUrl": "https://jobs.ashbyhq.com/liquid-ai/fe8596ae-becc-49d2-a3dd-f68ed74144a0/application", "descriptionHtml": "<h1><strong>Work With Us</strong></h1><p style=\"min-height:1.5em\">At Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.</p><p style=\"min-height:1.5em\">We believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.</p><p style=\"min-height:1.5em\"></p><p style=\"min-height:1.5em\"><em><strong>While San Francisco and Boston are preferred, we are open to other locations.</strong></em></p><p style=\"min-height:1.5em\"></p><h2><strong>This Role Is For You If:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">You want to play a critical role in the development of Liquid Vision-Language models</p></li><li><p style=\"min-height:1.5em\">Focus on gathering high-quality vision-language midtraining and SFT datasets</p></li></ul><h2><strong>Required Experience:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\"><strong>Experience Level:</strong> B.S. + 5 years experience or M.S. + 3 years experience or Ph.D. + 1 year of experience</p></li><li><p style=\"min-height:1.5em\"><strong>Dataset Engineering</strong>: Expertise in data curation, cleaning, augmentation, and synthetic data generation techniques</p></li><li><p style=\"min-height:1.5em\"><strong>Machine Learning Expertise:</strong> Ability to write and debug models in popular ML frameworks, and experience working with LLMs and VLMs</p></li><li><p style=\"min-height:1.5em\"><strong>Software Development</strong>: Strong programming skills in Python, with an emphasis on writing clean, maintainable, and scalable code</p></li></ul><h2><strong>Desired Experience:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">M.S. or Ph.D. in Computer Science, Electrical Engineering, Math, or a related field</p></li><li><p style=\"min-height:1.5em\">Experience fine-tuning or customizing LLMs and VLMs</p></li><li><p style=\"min-height:1.5em\">2+ years working in computer vision</p></li><li><p style=\"min-height:1.5em\">First-author publications in top ML or vision conferences (e.g. NeurIPS, ICML, ICLR, CVPR, ICCV)</p></li><li><p style=\"min-height:1.5em\">Contributions to popular open-source projects</p></li></ul><h2><strong>What You'll Actually Do:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Create and maintain data processing, cleaning, filtering, and selection pipeline that can handle image-text data</p></li><li><p style=\"min-height:1.5em\">Watch out for the release of public high quality VLM datasets</p></li><li><p style=\"min-height:1.5em\">Create and maintain synthetic data augmentation pipeline to enhance VLM data quality</p></li><li><p style=\"min-height:1.5em\">Work with the multimodal vision team to run ablations on new dataset</p></li></ul><h2><strong>What You'll Gain:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Hands-on experience with state-of-the-art technology at a leading AI company</p></li><li><p style=\"min-height:1.5em\">A collaborative, fast-paced environment where your work directly shapes our products and the next generation of LFMs</p></li></ul><p style=\"min-height:1.5em\"></p><h1><strong>About Liquid AI</strong></h1><p style=\"min-height:1.5em\">Spun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.</p>", "descriptionPlain": "WORK WITH US\n\nAt Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.\n\nWe believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.\n\nWhile San Francisco and Boston are preferred, we are open to other locations.\n\n\nTHIS ROLE IS FOR YOU IF:\n\n - You want to play a critical role in the development of Liquid Vision-Language models\n\n - Focus on gathering high-quality vision-language midtraining and SFT datasets\n\n\nREQUIRED EXPERIENCE:\n\n - Experience Level: B.S. + 5 years experience or M.S. + 3 years experience or Ph.D. + 1 year of experience\n\n - Dataset Engineering: Expertise in data curation, cleaning, augmentation, and synthetic data generation techniques\n\n - Machine Learning Expertise: Ability to write and debug models in popular ML frameworks, and experience working with LLMs and VLMs\n\n - Software Development: Strong programming skills in Python, with an emphasis on writing clean, maintainable, and scalable code\n\n\nDESIRED EXPERIENCE:\n\n - M.S. or Ph.D. in Computer Science, Electrical Engineering, Math, or a related field\n\n - Experience fine-tuning or customizing LLMs and VLMs\n\n - 2+ years working in computer vision\n\n - First-author publications in top ML or vision conferences (e.g. NeurIPS, ICML, ICLR, CVPR, ICCV)\n\n - Contributions to popular open-source projects\n\n\nWHAT YOU'LL ACTUALLY DO:\n\n - Create and maintain data processing, cleaning, filtering, and selection pipeline that can handle image-text data\n\n - Watch out for the release of public high quality VLM datasets\n\n - Create and maintain synthetic data augmentation pipeline to enhance VLM data quality\n\n - Work with the multimodal vision team to run ablations on new dataset\n\n\nWHAT YOU'LL GAIN:\n\n - Hands-on experience with state-of-the-art technology at a leading AI company\n\n - A collaborative, fast-paced environment where your work directly shapes our products and the next generation of LFMs\n\n\nABOUT LIQUID AI\n\nSpun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "a25b97f4-02ee-4453-a2e1-f8d5cfe2c4b4", "title": "Member of Technical Staff - Training Infrastructure Engineer", "department": "Research & Engineering", "team": "Research & Engineering", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [{"location": "Boston", "address": {"postalAddress": {"addressRegion": "Massachusetts", "addressCountry": "United States", "addressLocality": "Cambridge"}}}, {"location": "Remote", "address": {"postalAddress": {"addressCountry": "Remote"}}}], "publishedAt": "2025-07-29T21:40:50.841+00:00", "isListed": true, "isRemote": true, "address": {"postalAddress": {"addressRegion": "", "addressCountry": "United States", "addressLocality": ""}}, "jobUrl": "https://jobs.ashbyhq.com/liquid-ai/a25b97f4-02ee-4453-a2e1-f8d5cfe2c4b4", "applyUrl": "https://jobs.ashbyhq.com/liquid-ai/a25b97f4-02ee-4453-a2e1-f8d5cfe2c4b4/application", "descriptionHtml": "<h1><strong>Work With Us</strong></h1><p style=\"min-height:1.5em\">At Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.</p><p style=\"min-height:1.5em\">We believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.</p><p style=\"min-height:1.5em\"></p><p style=\"min-height:1.5em\"><em><strong>While San Francisco and Boston are preferred, we are open to other locations.</strong></em></p><p style=\"min-height:1.5em\"></p><h2><strong>This Role Is For You If:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">You have extensive experience building distributed training infrastructure for language and multimodal models, with hands-on expertise in frameworks like PyTorch Distributed, DeepSpeed, or Megatron-LM</p></li><li><p style=\"min-height:1.5em\">You're passionate about solving complex systems challenges in large-scale model training\u2014from efficient multimodal data loading to sophisticated sharding strategies to robust checkpointing mechanisms</p></li><li><p style=\"min-height:1.5em\">You have a deep understanding of hardware accelerators and networking topologies, with the ability to optimize communication patterns for different parallelism strategies</p></li><li><p style=\"min-height:1.5em\">You're skilled at identifying and resolving performance bottlenecks in training pipelines, whether they occur in data loading, computation, or communication between nodes</p></li><li><p style=\"min-height:1.5em\">You have experience working with diverse data types (text, images, video, audio) and can build data pipelines that handle heterogeneous inputs efficiently</p></li></ul><h2><strong>Desired Experience:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">You've implemented custom sharding techniques (tensor/pipeline/data parallelism) to scale training across distributed GPU clusters of varying sizes</p></li><li><p style=\"min-height:1.5em\">You have experience optimizing data pipelines for multimodal datasets with sophisticated preprocessing requirements</p></li><li><p style=\"min-height:1.5em\">You've built fault-tolerant checkpointing systems that can handle complex model states while minimizing training interruptions</p></li><li><p style=\"min-height:1.5em\">You've contributed to open-source training infrastructure projects or frameworks</p></li><li><p style=\"min-height:1.5em\">You've designed training infrastructure that works efficiently for both parameter-efficient specialized models and massive multimodal systems</p></li></ul><h2><strong>What You'll Actually Do:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Design and implement high-performance, scalable training infrastructure that efficiently utilizes our GPU clusters for both specialized and large-scale multimodal models</p></li><li><p style=\"min-height:1.5em\">Build robust data loading systems that eliminate I/O bottlenecks and enable training on diverse multimodal datasets</p></li><li><p style=\"min-height:1.5em\">Develop sophisticated checkpointing mechanisms that balance memory constraints with recovery needs across different model scales</p></li><li><p style=\"min-height:1.5em\">Optimize communication patterns between nodes to minimize the overhead of distributed training for long-running experiments</p></li><li><p style=\"min-height:1.5em\">Collaborate with ML engineers to implement new model architectures and training algorithms at scale</p></li><li><p style=\"min-height:1.5em\">Create monitoring and debugging tools to ensure training stability and resource efficiency across our infrastructure</p></li></ul><h2><strong>What You'll Gain:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">The opportunity to solve some of the hardest systems challenges in AI, working at the intersection of distributed systems and cutting-edge multimodal machine learning</p></li><li><p style=\"min-height:1.5em\">Experience building infrastructure that powers the next generation of foundation models across the full spectrum of model scales</p></li><li><p style=\"min-height:1.5em\">The satisfaction of seeing your work directly enable breakthroughs in model capabilities and performance</p></li></ul><p style=\"min-height:1.5em\"></p><h1><strong>About Liquid AI</strong></h1><p style=\"min-height:1.5em\">Spun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.</p>", "descriptionPlain": "WORK WITH US\n\nAt Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.\n\nWe believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.\n\nWhile San Francisco and Boston are preferred, we are open to other locations.\n\n\nTHIS ROLE IS FOR YOU IF:\n\n - You have extensive experience building distributed training infrastructure for language and multimodal models, with hands-on expertise in frameworks like PyTorch Distributed, DeepSpeed, or Megatron-LM\n\n - You're passionate about solving complex systems challenges in large-scale model training\u2014from efficient multimodal data loading to sophisticated sharding strategies to robust checkpointing mechanisms\n\n - You have a deep understanding of hardware accelerators and networking topologies, with the ability to optimize communication patterns for different parallelism strategies\n\n - You're skilled at identifying and resolving performance bottlenecks in training pipelines, whether they occur in data loading, computation, or communication between nodes\n\n - You have experience working with diverse data types (text, images, video, audio) and can build data pipelines that handle heterogeneous inputs efficiently\n\n\nDESIRED EXPERIENCE:\n\n - You've implemented custom sharding techniques (tensor/pipeline/data parallelism) to scale training across distributed GPU clusters of varying sizes\n\n - You have experience optimizing data pipelines for multimodal datasets with sophisticated preprocessing requirements\n\n - You've built fault-tolerant checkpointing systems that can handle complex model states while minimizing training interruptions\n\n - You've contributed to open-source training infrastructure projects or frameworks\n\n - You've designed training infrastructure that works efficiently for both parameter-efficient specialized models and massive multimodal systems\n\n\nWHAT YOU'LL ACTUALLY DO:\n\n - Design and implement high-performance, scalable training infrastructure that efficiently utilizes our GPU clusters for both specialized and large-scale multimodal models\n\n - Build robust data loading systems that eliminate I/O bottlenecks and enable training on diverse multimodal datasets\n\n - Develop sophisticated checkpointing mechanisms that balance memory constraints with recovery needs across different model scales\n\n - Optimize communication patterns between nodes to minimize the overhead of distributed training for long-running experiments\n\n - Collaborate with ML engineers to implement new model architectures and training algorithms at scale\n\n - Create monitoring and debugging tools to ensure training stability and resource efficiency across our infrastructure\n\n\nWHAT YOU'LL GAIN:\n\n - The opportunity to solve some of the hardest systems challenges in AI, working at the intersection of distributed systems and cutting-edge multimodal machine learning\n\n - Experience building infrastructure that powers the next generation of foundation models across the full spectrum of model scales\n\n - The satisfaction of seeing your work directly enable breakthroughs in model capabilities and performance\n\n\nABOUT LIQUID AI\n\nSpun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "827b68ad-3e29-4334-91d0-9722e01547df", "title": "Member of Technical Staff - Frontend Engineer", "department": "Product", "team": "Product", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [{"location": "Boston", "address": {"postalAddress": {"addressRegion": "Massachusetts", "addressCountry": "United States", "addressLocality": "Cambridge"}}}, {"location": "Remote", "address": {"postalAddress": {"addressCountry": "Remote"}}}], "publishedAt": "2025-10-24T20:59:33.414+00:00", "isListed": true, "isRemote": true, "address": {"postalAddress": {"addressRegion": "", "addressCountry": "United States", "addressLocality": ""}}, "jobUrl": "https://jobs.ashbyhq.com/liquid-ai/827b68ad-3e29-4334-91d0-9722e01547df", "applyUrl": "https://jobs.ashbyhq.com/liquid-ai/827b68ad-3e29-4334-91d0-9722e01547df/application", "descriptionHtml": "<h1><strong>Work With Us</strong></h1><p style=\"min-height:1.5em\">At Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.</p><p style=\"min-height:1.5em\">We believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.</p><p style=\"min-height:1.5em\"></p><p style=\"min-height:1.5em\"><em><strong>While San Francisco and Boston are preferred, we are open to other locations in United States.</strong></em></p><p style=\"min-height:1.5em\"></p><h2><strong>This Role Is For You If:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">You thrive on bringing technical depth and design precision together in your work.</p></li><li><p style=\"min-height:1.5em\">You care deeply about performance, accessibility, and user experience.</p></li><li><p style=\"min-height:1.5em\">You think in systems \u2014 building components that scale, not just pages that work.</p></li><li><p style=\"min-height:1.5em\">You\u2019re energized by translating complex ML capabilities into elegant, usable products.</p></li><li><p style=\"min-height:1.5em\">You balance polish and pragmatism \u2014 knowing when to prototype and when to perfect.</p></li></ul><h2><strong>Desired Experience:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Strong proficiency with <strong>TypeScript, React,</strong> and modern frontend tooling (Vite, Next.js, etc.)</p></li><li><p style=\"min-height:1.5em\">Experience designing and implementing <strong>modular UI architectures</strong> and <strong>design systems</strong></p></li><li><p style=\"min-height:1.5em\">Deep understanding of<strong> state management, API integration, and performance optimization</strong></p></li><li><p style=\"min-height:1.5em\">Experience working closely with backend and ML teams to bring complex data and functionality to life</p></li><li><p style=\"min-height:1.5em\">A product-focused mindset \u2014 empathy for users, attention to interaction detail, and a bias for clarity</p></li></ul><h2><strong>What You'll Actually Do:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Architect and build <strong>front-end systems </strong>for internal and external Liquid products</p></li><li><p style=\"min-height:1.5em\">Create intuitive<strong> interfaces</strong> that make advanced ML systems accessible and actionable</p></li><li><p style=\"min-height:1.5em\">Collaborate with backend, product, and research teams to design seamless data flows</p></li><li><p style=\"min-height:1.5em\">Develop <strong>high-performance, scalable UIs</strong> that run smoothly across browsers and devices</p></li><li><p style=\"min-height:1.5em\">Contribute to the evolution of our <strong>design system</strong> and front-end best practices</p></li><li><p style=\"min-height:1.5em\">Help define the technical standards and workflows for Liquid\u2019s front-end development culture</p></li></ul><h2><strong>What You'll Gain:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">The opportunity to define how advanced AI systems are <strong>experienced and interacted with</strong></p></li><li><p style=\"min-height:1.5em\">Deep collaboration with world-class ML researchers and platform engineers</p></li><li><p style=\"min-height:1.5em\">Influence over critical product and UX decisions shaping Liquid\u2019s next-generation tools</p></li><li><p style=\"min-height:1.5em\">A chance to build front-end systems at a <strong>true greenfield stage</strong> \u2014 no legacy, just possibility</p><p style=\"min-height:1.5em\"></p></li></ul><h1><strong>About Liquid AI</strong></h1><p style=\"min-height:1.5em\">Spun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.</p>", "descriptionPlain": "WORK WITH US\n\nAt Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.\n\nWe believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.\n\nWhile San Francisco and Boston are preferred, we are open to other locations in United States.\n\n\nTHIS ROLE IS FOR YOU IF:\n\n - You thrive on bringing technical depth and design precision together in your work.\n\n - You care deeply about performance, accessibility, and user experience.\n\n - You think in systems \u2014 building components that scale, not just pages that work.\n\n - You\u2019re energized by translating complex ML capabilities into elegant, usable products.\n\n - You balance polish and pragmatism \u2014 knowing when to prototype and when to perfect.\n\n\nDESIRED EXPERIENCE:\n\n - Strong proficiency with TypeScript, React, and modern frontend tooling (Vite, Next.js, etc.)\n\n - Experience designing and implementing modular UI architectures and design systems\n\n - Deep understanding of state management, API integration, and performance optimization\n\n - Experience working closely with backend and ML teams to bring complex data and functionality to life\n\n - A product-focused mindset \u2014 empathy for users, attention to interaction detail, and a bias for clarity\n\n\nWHAT YOU'LL ACTUALLY DO:\n\n - Architect and build front-end systems for internal and external Liquid products\n\n - Create intuitive interfaces that make advanced ML systems accessible and actionable\n\n - Collaborate with backend, product, and research teams to design seamless data flows\n\n - Develop high-performance, scalable UIs that run smoothly across browsers and devices\n\n - Contribute to the evolution of our design system and front-end best practices\n\n - Help define the technical standards and workflows for Liquid\u2019s front-end development culture\n\n\nWHAT YOU'LL GAIN:\n\n - The opportunity to define how advanced AI systems are experienced and interacted with\n\n - Deep collaboration with world-class ML researchers and platform engineers\n\n - Influence over critical product and UX decisions shaping Liquid\u2019s next-generation tools\n\n - A chance to build front-end systems at a true greenfield stage \u2014 no legacy, just possibility\n\n\nABOUT LIQUID AI\n\nSpun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "4342f34f-3694-4366-a1f8-a60725d7d0e2", "title": "Member of Technical Staff - ML Inference Engineer, Pytorch", "department": "Research & Engineering", "team": "Research & Engineering", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [{"location": "Boston", "address": {"postalAddress": {"addressRegion": "Massachusetts", "addressCountry": "United States", "addressLocality": "Cambridge"}}}], "publishedAt": "2025-07-29T22:21:25.288+00:00", "isListed": true, "isRemote": true, "address": {"postalAddress": {"addressRegion": "", "addressCountry": "United States", "addressLocality": ""}}, "jobUrl": "https://jobs.ashbyhq.com/liquid-ai/4342f34f-3694-4366-a1f8-a60725d7d0e2", "applyUrl": "https://jobs.ashbyhq.com/liquid-ai/4342f34f-3694-4366-a1f8-a60725d7d0e2/application", "descriptionHtml": "<h1><strong>Work With Us</strong></h1><p style=\"min-height:1.5em\">At Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.</p><p style=\"min-height:1.5em\">We believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.</p><p style=\"min-height:1.5em\"></p><h2><strong>This Role Is For You If:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">You have experience building large-scale production stacks for model serving</p></li><li><p style=\"min-height:1.5em\">You have a solid understanding of ragged batching, dynamic load balancing, KV-cache management, and other multi-tenant serving techniques</p></li><li><p style=\"min-height:1.5em\">You have experience with applying quantization strategies (e.g., FP8, INT4) while safeguarding model accuracy</p></li><li><p style=\"min-height:1.5em\">You have deployed models in both single-GPU and multi-GPU environments and can diagnose performance issues across the stack</p></li></ul><h2><strong>Desired Experience:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">PyTorch</p></li><li><p style=\"min-height:1.5em\">Python</p></li><li><p style=\"min-height:1.5em\">Model-serving frameworks (e.g. TensorRT, vLLM, SGLang)</p></li></ul><h2><strong>What You'll Actually Do:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Optimize and productionize the end-to-end pipeline for GPU model inference around Liquid Foundation Models (LFMs)</p></li><li><p style=\"min-height:1.5em\">Facilitate the development of next-generation Liquid Foundation Models from the lens of GPU inference</p></li><li><p style=\"min-height:1.5em\">Profile and robustify the stack for different batching and serving requirements</p></li><li><p style=\"min-height:1.5em\">Build and scale pipelines for test-time compute</p></li></ul><h2><strong>What You'll Gain:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Hands-on experience with state-of-the-art technology at a leading AI company</p></li><li><p style=\"min-height:1.5em\">Deeper expertise in machine learning systems and efficient large model inference</p></li><li><p style=\"min-height:1.5em\">Opportunity to scale pipelines that directly influence user latency and experience with Liquid's models</p></li><li><p style=\"min-height:1.5em\">A collaborative, fast-paced environment where your work directly shapes our products and the next generation of LFMs</p></li></ul><p style=\"min-height:1.5em\"></p><h1><strong>About Liquid AI</strong></h1><p style=\"min-height:1.5em\">Spun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.</p>", "descriptionPlain": "WORK WITH US\n\nAt Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.\n\nWe believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.\n\n\nTHIS ROLE IS FOR YOU IF:\n\n - You have experience building large-scale production stacks for model serving\n\n - You have a solid understanding of ragged batching, dynamic load balancing, KV-cache management, and other multi-tenant serving techniques\n\n - You have experience with applying quantization strategies (e.g., FP8, INT4) while safeguarding model accuracy\n\n - You have deployed models in both single-GPU and multi-GPU environments and can diagnose performance issues across the stack\n\n\nDESIRED EXPERIENCE:\n\n - PyTorch\n\n - Python\n\n - Model-serving frameworks (e.g. TensorRT, vLLM, SGLang)\n\n\nWHAT YOU'LL ACTUALLY DO:\n\n - Optimize and productionize the end-to-end pipeline for GPU model inference around Liquid Foundation Models (LFMs)\n\n - Facilitate the development of next-generation Liquid Foundation Models from the lens of GPU inference\n\n - Profile and robustify the stack for different batching and serving requirements\n\n - Build and scale pipelines for test-time compute\n\n\nWHAT YOU'LL GAIN:\n\n - Hands-on experience with state-of-the-art technology at a leading AI company\n\n - Deeper expertise in machine learning systems and efficient large model inference\n\n - Opportunity to scale pipelines that directly influence user latency and experience with Liquid's models\n\n - A collaborative, fast-paced environment where your work directly shapes our products and the next generation of LFMs\n\n\nABOUT LIQUID AI\n\nSpun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "3914c96f-0fbe-4bae-92fa-5a98f9a927f1", "title": "Member of Technical Staff - Backend Engineer", "department": "Product", "team": "Product", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [{"location": "Boston", "address": {"postalAddress": {"addressRegion": "Massachusetts", "addressCountry": "United States", "addressLocality": "Cambridge"}}}, {"location": "Remote", "address": {"postalAddress": {"addressCountry": "Remote"}}}], "publishedAt": "2025-09-09T14:00:21.485+00:00", "isListed": true, "isRemote": true, "address": {"postalAddress": {"addressRegion": "", "addressCountry": "United States", "addressLocality": ""}}, "jobUrl": "https://jobs.ashbyhq.com/liquid-ai/3914c96f-0fbe-4bae-92fa-5a98f9a927f1", "applyUrl": "https://jobs.ashbyhq.com/liquid-ai/3914c96f-0fbe-4bae-92fa-5a98f9a927f1/application", "descriptionHtml": "<h1><strong>Work With Us</strong></h1><p style=\"min-height:1.5em\">At Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.</p><p style=\"min-height:1.5em\">We believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.</p><p style=\"min-height:1.5em\"></p><p style=\"min-height:1.5em\"><em><strong>While San Francisco and Boston are preferred, we are open to other locations in United States.</strong></em></p><p style=\"min-height:1.5em\"></p><h2><strong>This Role Is For You If:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">You thrive on building systems from the ground up, not just maintaining them</p></li><li><p style=\"min-height:1.5em\">You understand that good infrastructure is the difference between theoretical and practical ML</p></li><li><p style=\"min-height:1.5em\">You balance pragmatism and ambition\u2014knowing when to push for scale and when to ship</p></li><li><p style=\"min-height:1.5em\">You\u2019re excited by the challenge of turning complex ML capabilities into intuitive products</p></li></ul><h2><strong>Desired Experience:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Proven track record of architecting and scaling systems from scratch</p></li><li><p style=\"min-height:1.5em\">Deep understanding of modern software architecture and best practices</p></li><li><p style=\"min-height:1.5em\">Experience deploying ML-powered systems in real-world production environments</p></li><li><p style=\"min-height:1.5em\">Strong opinions about engineering practices\u2014backed by hard-earned lessons</p></li><li><p style=\"min-height:1.5em\">Ability to decide when to build vs. when to leverage existing tools</p></li></ul><h2><strong>What You'll Actually Do:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Architect and implement full-stack solutions for both internal platforms and customer-facing products</p></li><li><p style=\"min-height:1.5em\">Design and scale backend services that enable robust ML model deployment</p></li><li><p style=\"min-height:1.5em\">Build deployment infrastructure that runs seamlessly across cloud and on-premise environments</p></li><li><p style=\"min-height:1.5em\">Develop interfaces that make complex ML systems accessible and usable</p></li><li><p style=\"min-height:1.5em\">Establish workflows that accelerate ML research-to-deployment cycles</p></li><li><p style=\"min-height:1.5em\">Collaborate closely with Product and ML teams to iterate quickly and effectively</p></li></ul><h2><strong>What You'll Gain:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">The chance to architect foundational systems at a true greenfield stage</p></li><li><p style=\"min-height:1.5em\">Direct collaboration with exceptional ML researchers and product builders</p></li><li><p style=\"min-height:1.5em\">Influence over critical technical decisions that will define Liquid\u2019s trajectory</p></li><li><p style=\"min-height:1.5em\">The opportunity to shape how enterprises deploy efficient AI models at scale</p></li></ul><p style=\"min-height:1.5em\"></p><h1><strong>About Liquid AI</strong></h1><p style=\"min-height:1.5em\">Spun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.</p>", "descriptionPlain": "WORK WITH US\n\nAt Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.\n\nWe believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.\n\nWhile San Francisco and Boston are preferred, we are open to other locations in United States.\n\n\nTHIS ROLE IS FOR YOU IF:\n\n - You thrive on building systems from the ground up, not just maintaining them\n\n - You understand that good infrastructure is the difference between theoretical and practical ML\n\n - You balance pragmatism and ambition\u2014knowing when to push for scale and when to ship\n\n - You\u2019re excited by the challenge of turning complex ML capabilities into intuitive products\n\n\nDESIRED EXPERIENCE:\n\n - Proven track record of architecting and scaling systems from scratch\n\n - Deep understanding of modern software architecture and best practices\n\n - Experience deploying ML-powered systems in real-world production environments\n\n - Strong opinions about engineering practices\u2014backed by hard-earned lessons\n\n - Ability to decide when to build vs. when to leverage existing tools\n\n\nWHAT YOU'LL ACTUALLY DO:\n\n - Architect and implement full-stack solutions for both internal platforms and customer-facing products\n\n - Design and scale backend services that enable robust ML model deployment\n\n - Build deployment infrastructure that runs seamlessly across cloud and on-premise environments\n\n - Develop interfaces that make complex ML systems accessible and usable\n\n - Establish workflows that accelerate ML research-to-deployment cycles\n\n - Collaborate closely with Product and ML teams to iterate quickly and effectively\n\n\nWHAT YOU'LL GAIN:\n\n - The chance to architect foundational systems at a true greenfield stage\n\n - Direct collaboration with exceptional ML researchers and product builders\n\n - Influence over critical technical decisions that will define Liquid\u2019s trajectory\n\n - The opportunity to shape how enterprises deploy efficient AI models at scale\n\n\nABOUT LIQUID AI\n\nSpun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}, {"id": "5ffdf938-a578-4c72-a7bb-f4152b7be45a", "title": "Member of Technical Staff - Product Designer", "department": "Product", "team": "Product", "employmentType": "FullTime", "location": "San Francisco", "shouldDisplayCompensationOnJobPostings": false, "secondaryLocations": [{"location": "Boston", "address": {"postalAddress": {"addressRegion": "Massachusetts", "addressCountry": "United States", "addressLocality": "Cambridge"}}}, {"location": "Remote", "address": {"postalAddress": {"addressCountry": "Remote"}}}], "publishedAt": "2025-10-24T20:45:19.023+00:00", "isListed": true, "isRemote": true, "address": {"postalAddress": {"addressRegion": "", "addressCountry": "United States", "addressLocality": ""}}, "jobUrl": "https://jobs.ashbyhq.com/liquid-ai/5ffdf938-a578-4c72-a7bb-f4152b7be45a", "applyUrl": "https://jobs.ashbyhq.com/liquid-ai/5ffdf938-a578-4c72-a7bb-f4152b7be45a/application", "descriptionHtml": "<h1><strong>Work With Us</strong></h1><p style=\"min-height:1.5em\">At Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.</p><p style=\"min-height:1.5em\">We believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.</p><p style=\"min-height:1.5em\"></p><p style=\"min-height:1.5em\"><em><strong>While San Francisco and Boston are preferred, we are open to other locations in United States.</strong></em></p><p style=\"min-height:1.5em\"></p><h2><strong>This Role Is For You If:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">You thrive at the intersection of complex systems and elegant design</p></li><li><p style=\"min-height:1.5em\">You\u2019re passionate about making advanced AI workflows approachable and visual</p></li><li><p style=\"min-height:1.5em\">You have strong empathy for technical users who aren\u2019t ML experts</p></li><li><p style=\"min-height:1.5em\">You enjoy working in fast-moving, research-driven environments where products evolve rapidly</p></li><li><p style=\"min-height:1.5em\">You get energy from designing products that make cutting-edge technology feel simple and human</p></li></ul><h2><strong>Desired Experience:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">4+ years of experience designing complex tools or platforms\u2014ideally developer tools, AI interfaces, or creative software</p></li><li><p style=\"min-height:1.5em\">Portfolio that demonstrates systems thinking and exceptional interaction design craft</p></li><li><p style=\"min-height:1.5em\">Proven ability to translate technical complexity into intuitive, usable products</p></li><li><p style=\"min-height:1.5em\">Experience collaborating closely with engineering and ML research teams</p></li><li><p style=\"min-height:1.5em\">Comfort designing for iterative, experimental environments where learning happens through prototyping</p></li></ul><h2><strong>What You'll Actually Do:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">Lead product design for a new generation of AI customization and deployment tools</p></li><li><p style=\"min-height:1.5em\">Design intuitive flows that make it easy for users to describe tasks, adapt models, and visualize results</p></li><li><p style=\"min-height:1.5em\">Work closely with Product and ML teams to shape experiences that feel like building with AI rather than configuring systems</p></li><li><p style=\"min-height:1.5em\">Develop interaction patterns and visual frameworks for model iteration, feedback, and performance understanding</p></li><li><p style=\"min-height:1.5em\">Establish design systems and principles that scale across multiple AI-driven products</p></li></ul><h2><strong>What You'll Gain:</strong></h2><ul style=\"min-height:1.5em\"><li><p style=\"min-height:1.5em\">The opportunity to define the design language for next-generation AI interfaces</p></li><li><p style=\"min-height:1.5em\">Deep collaboration with world-class ML researchers and engineers</p></li><li><p style=\"min-height:1.5em\">Influence over how developers and enterprises build with efficient, deployable models</p></li><li><p style=\"min-height:1.5em\">A front-row seat in shaping how humans interact with intelligence itself</p><p style=\"min-height:1.5em\"></p></li></ul><h1><strong>About Liquid AI</strong></h1><p style=\"min-height:1.5em\">Spun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.</p><p style=\"min-height:1.5em\"></p>", "descriptionPlain": "WORK WITH US\n\nAt Liquid, we\u2019re not just building AI models\u2014we\u2019re redefining the architecture of intelligence itself. Spun out of MIT, our mission is to build efficient AI systems at every scale. Our Liquid Foundation Models (LFMs) operate where others can\u2019t: on-device, at the edge, under real-time constraints. We\u2019re not iterating on old ideas\u2014we\u2019re architecting what comes next.\n\nWe believe great talent powers great technology. The Liquid team is a community of world-class engineers, researchers, and builders creating the next generation of AI. Whether you're helping shape model architectures, scaling our dev platforms, or enabling enterprise deployments\u2014your work will directly shape the frontier of intelligent systems.\n\nWhile San Francisco and Boston are preferred, we are open to other locations in United States.\n\n\nTHIS ROLE IS FOR YOU IF:\n\n - You thrive at the intersection of complex systems and elegant design\n\n - You\u2019re passionate about making advanced AI workflows approachable and visual\n\n - You have strong empathy for technical users who aren\u2019t ML experts\n\n - You enjoy working in fast-moving, research-driven environments where products evolve rapidly\n\n - You get energy from designing products that make cutting-edge technology feel simple and human\n\n\nDESIRED EXPERIENCE:\n\n - 4+ years of experience designing complex tools or platforms\u2014ideally developer tools, AI interfaces, or creative software\n\n - Portfolio that demonstrates systems thinking and exceptional interaction design craft\n\n - Proven ability to translate technical complexity into intuitive, usable products\n\n - Experience collaborating closely with engineering and ML research teams\n\n - Comfort designing for iterative, experimental environments where learning happens through prototyping\n\n\nWHAT YOU'LL ACTUALLY DO:\n\n - Lead product design for a new generation of AI customization and deployment tools\n\n - Design intuitive flows that make it easy for users to describe tasks, adapt models, and visualize results\n\n - Work closely with Product and ML teams to shape experiences that feel like building with AI rather than configuring systems\n\n - Develop interaction patterns and visual frameworks for model iteration, feedback, and performance understanding\n\n - Establish design systems and principles that scale across multiple AI-driven products\n\n\nWHAT YOU'LL GAIN:\n\n - The opportunity to define the design language for next-generation AI interfaces\n\n - Deep collaboration with world-class ML researchers and engineers\n\n - Influence over how developers and enterprises build with efficient, deployable models\n\n - A front-row seat in shaping how humans interact with intelligence itself\n\n\nABOUT LIQUID AI\n\nSpun out of MIT CSAIL, we\u2019re a foundation model company headquartered in Boston. Our mission is to build capable and efficient general-purpose AI systems at every scale\u2014from phones and vehicles to enterprise servers and embedded chips. Our models are designed to run where others stall: on CPUs, with low latency, minimal memory, and maximum reliability. We\u2019re already partnering with global enterprises across consumer electronics, automotive, life sciences, and financial services. And we\u2019re just getting started.", "compensation": {"compensationTierSummary": null, "scrapeableCompensationSalarySummary": null, "compensationTiers": [], "summaryComponents": []}}], "apiVersion": "1"}